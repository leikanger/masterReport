
\section{A Theoretical Comparison of the two Models}
\label{secComparisonOfTheTwoModels}

	%TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
	% Test denne for større og mindre aktivitetsnivå! for større aktivitetsnivå vil KM komme bedre ut!
	% 	Faila, fordi NIM nodene ikkje får synaptisk input, men sensory function. This almost the same as the activation level of a $\kappa M-node

	%TODO Eg har lovet at 	the most important elements that differ between the two models will be presented in sec. [THIS SECTION]. TODO Gjør dette TODO

% 	\subsection{On Implementation Complexity} TODO TODO
%	TODO %TODO Her skal hovudresultatet i forskjellen i implementasjon stå. Også: Write about $\kappa M$ as a Moore automata and that a Moore automata generally gives a more efficient implementation, but is harder to implement.
%	%	Skriv en-eller-annen--plass at når man gjekk fra 1. og 2. generasjon ANN til 3. generasjon ANN, det er mulig å sei at man begynte å "consider a Moore automata of the neuron".
%	%	(Dette er en litt løs tolking, siden ouput er gitt som discrete pulser. Eg trur likevel at den er gyldig..)
%	%	(Her er det bare state som gir ouput).
%	%
%	%	I min nye modell, tar eg dette videre, og innfører at output også er gitt av present input til neuronet. Dette gir oss en Mealy automata av neuronet.
%	%	Skriv litt om Moore vs. Mealy automata!



%TODO TODO TODO Flytt neste greiene til kap 3.4 TODO TODO TODO
%TODO SLETT! Dette står nå 3.3.1 og 3.3.2 TODO
%	\subsection{Spatio-Temporal Delay for the Two Models} %TODO TODO TODO Skriv denne, bra! (Har nå kopiert den over fra "designOfTheImplementation.tex"
% 			\subsubsection{Spatiotemporal simulation in $NIM$}
% 			In a $NIM$ simulation, synaptic transmission is simulated by \emph{s\_synapse::doTask()} calling the postsynaptic node's \emph{newInputSignal(\emph{double})}, located in the dendrite. %\emph{s\_dendrite}.
% 			This function adds the size of the transmission to the node's depolarization variable and checks whether it crossed the firing threshold.
% 			If the depolarization is beyond the firing threshold, the node's \emph{s\_auron} pointer is pushed to the back of \emph{pWorkTaskQueue}.
% % 			In this case it inserts the node's \emph{s\_auron} pointer to the back of \emph{pWorkTaskQueue}.
% 			%Synaptic transmission is simulated by \emph{synapse::doTask()} calling the postsynaptic node's \emph{s\_dendrite::newInputSignal(\emph{double})}, located in the dendrite.
% 			%In the $NIM$ implementation, this function adds the size of the transmission to the node's activation variable and when the node's depolarization crosses the firing threshold, 
% 				%its \emph{s\_auron} pointer is pushed to the back of \emph{pWorkTaskQueue}.
% 			%%% Eller:
% 			%In the $NIM$ implementation, this function adds the size of the transmission defined by the synaptic weight to the node's depolarization variable.
% 			%When the node's depolarization crosses the firing threshold, the node is scheduled for firing by the dendrite element inserting its auron pointer to the back of \mbox{\emph{pWorkTaskQueue}}.
% 			%If the node's depolarization crosses the firing threshold, the \emph{s\_auron} subelement is scheduled for execution by letting \emph{s\_dendrite} push its pointer to the back of \mbox{\emph{pWorkTaskQueue}}.
% 			
% 			The \emph{s\_auron::doTask()} function resets the node's depolarization, and inserts the address of the first \emph{s\_axon} element to \emph{pWorkTaskQueue}.
% 			The neuron's axon can be implemented as a linked list of \emph{s\_axon} subelements, representing a series of axon compartments.
% 			%This enables a precise simulation of the axon's spatiotemporal delay as there is a delay of one time step per axon compartment.
% 			Small computational time steps and a large number of serially linked axon elements create a more precise simulation of the spatio--temporal delay before any particular synapse.
% 			%This enables a precise simulation of the axon's spatiotemporal delay by simulating a delay of one iteration per axon compartment.
% 			When the pointer to a synapse is located in the axon compartment, that pointer is also inserted into \emph{pWorkTaskQueue}.
% 			Thus, a synaptic transmission is initiated after the synapse's predefined spatio--temporal delay.
% % 			Synaptic transmission is thus initiated after the synapse's predefined spatiotemporal delay.

% 			\subsubsection{Spatiotemporal simulation in $\kappa M$}
% 			In a $\kappa M$ simulation, spatio--temporal delay can be simulated by utilizing the native task scheduling capabilities of $\kappa M$;
% 			As the task scheduler use a member variable from \emph{class timeInterface}, task scheduling can be used for objects of any class derived from \emph{timeInterface}.
% 			When the neuron fires, the auron object of the node can write to all the node's output synapses' \emph{dEstimatedTaskTime} variable.
% 			It is written to be the present time plus the predefined spatio--temporal delay.
% 			In this way, axonic delay can be simulated in a more efficient manner.
% 			This method also gives a temporal resolution defined by the floating point data format.  %In this way, a more efficient axonic delay can be simulated with floating point accuracy.
% 
% 			This way of simulating spatio--temporal delay can also be implemented for a $NIM$ simulation.
% 			The ability to define intra--iteration times of transmission will not be as advantageous for $NIM$ as for the $\kappa M$ simulation method, 
% 				and it is unknown whether the introduction of a task scheduler improves the computational efficiency of a $NIM$ simulation. %can be used to create a more effective simulation.

%TODO TODO TODO Flytt section'en over TIL 3.4: A theoretical comparison of the two models TODO TODO TODO


	\subsection{On Computational Complexity}
	\label{ssecOnComputationalComlexity}
		A $\kappa M$ simulation involves more complex operations than in a $NIM$ simulation.
		To assess whether it takes longer time to simulate, a quick experiment was set up. 
%%%%
		A set of runs of $auroSim$ have been executed to compare the run time of the experiment that produced the simulated solution in experiment 2 (see section \ref{ssecExperiment2Design}).
		All simulations were conducted with the same parameters, using either the $\kappa M$ or the $NIM$ simulation model.
% 		Both runs were conducted with the same call, but compiled with either only the $\kappa M$ or the $NIM$ simulation model.
		The run time of the two variants of $auroSim$ was found by the command
\begin{quote}
	\emph{time ./auroSim.out -r1000000 -n1.5}
\end{quote}
		This executes a simulation with $1.5$ forcing function periods, each with $10^6$ time steps.
		The mean output of the $time$ shell command, for $\kappa M$ and $NIM$, is presented in table \ref{tabRunTimesForImplementationOfSANNandKM}.
% 		Representative output of the $time$ shell command for the two compilations are presented in table \ref{tabRunTimesForImplementationOfSANNandKM}.
%		A representative output of the $time$ shell command for the two compilations is presented in table \ref{tabRunTimesForImplementationOfSANNandKM}.

	\begin{table}[hbp!t]
		\centering
		\begin{tabular}{|l|cc|cc|}
			\hline 
			& $NIM_{1.000.000}$ &  & $\kappa M_{1.000.000}$ & \\
			& Mean & Std. dev. & Mean & Std. dev.  \\
			\hline
			run 	& 0.434s 	& 	0.104 	& 0.800s 	& 0.088 \\
			user 	& 0.336s 	&	0.337 	& 0.703s  & 0.079 \\
			sys 	& 0.007s 	& 	0.003	& 0.009s  & 0.007
			\\ \hline 
		\end{tabular}
		\caption[Mean run time for ten runs of the $NIM$ and $\kappa M$ version of $auroSim$]{
			Mean run time for ten runs of the $NIM$ and the $\kappa M$ version of $auroSim$.
			The standard deviation for all items is also listed.
			The interested reader is referred to appendix \ref{appendixOutputOfTimeCommand} for the run time of all runs in the experiment.
			}
		\label{tabRunTimesForImplementationOfSANNandKM}
	\end{table}


		The $\kappa M$ simulations required almost the double amount of `wall clock time' in these particular runs of auroSim.
%  		The $\kappa M$ simulations required almost the double amount of 'wall clock time' in the runs conducted to assess run--time efficiency of the two implementations. %for this particular run. 
% 		A representative output of the $time$ shell command is presented in table \ref{tabRunTimesForImplementationOfSANNandKM}, and shows that the $\kappa M$ simulation required almost the double amount of 'wall clock time' for this particular run. %for simulating a neuron with the same temporal resolution as the $NIM$ simulation.
		A comprehensive study of the run time of the two simulation models has not been conducted, since the relative run times of the two models is hardware--dependent and would only give an example for this specific architecture.
		The results still indicate that the $\kappa M$ implementation requires more computational resources than the $NIM$ implementation.
		This is most probably due to the computational complexity of $\kappa M$.
% 		If executed on specialized hardware for floating point operations, like a Graphical Processing Unit, the relative run time may be improved. %the figures may be improved.



% 		These results could represent the reason why the $\kappa M$ simulation scheme has not been implemented before;
% 			it is un--intuitive that a slower implementation can give more effective simulations. % of a system.

		Because the principal goal of a simulation is to produce accurate results, and the error can be decreased by making the computational time steps smaller, 
			it is possible to measure efficiency by the simulation method's error\cite{PlesserStraubeMorrisonPlesser2007}.
% 			the accuracy of a simulation method can be used as a measure on its efficiency\cite{PlesserStraubeMorrisonPlesser2007}.
		The run times in table \ref{tabRunTimesForImplementationOfSANNandKM} put large requirements on $\kappa M$ in order for this method to be more effective than $NIM$.
%		The run time indicated in table \ref{tabRunTimesForImplementationOfSANNandKM} put large requirements on $\kappa M$ in order for this method to be more effective than $NIM$.
		A comparative efficiency analysis, based on simulation accuracy, is presented in chapter \ref{chExperimentalEfficiencyMeasurement}.
% 		A comparative efficiency analysis based on experimental results is presented in chapter \ref{chExperimentalEfficiencyMeasurement}.






	

	\subsection{Time and Error for the Two Models}
	 	\label{ssecAnalysisOfErrorsForTheTwoModels}
	
        When simulating time variant variables in discrete--time environments, truncation errors arise from the discretization of time.
		Mechanisms than make the variable time variant are computed based on the previously updated value instead of continuously updating the  value.
		For a $NIM$ simulation, this means that all depolarizing input and the effect of leakage during a time step does not influence the total size of that time step's leakage.
		This effect is larger for simulations with longer computational time steps.
% 		The effect of this is larger for simulations with longer computational time steps.
		As mentioned in section \ref{secSpikingANNBackgroundInfo}, a simulation with a smaller error can therefore easily be designed by increasing the temporal resolution of the simulation.
		This is not a good solution, as it also greatly increases the computational load of the simulation. 

        Because the Numerical Integration Model($NIM$) is fundamentally different from a simulation model that considers depolarizing flow($\kappa M$),
			the two models' error mechanisms are analyzed separately.
        All analysis done in this text are of the un--improved models, implemented with a simple sample--and--hold numerical technique.
        Optimization by estimating the intermediate values in each time step can be utilized for both models, but this is outside the scope of this work.



	\subsubsection{Numerical Integration Method($NIM$)}
		The considered variable in a $NIM$ simulation is the depolarization value of the neuron.
		An inter--spike interval is completed when this value goes to suprathreshold levels, causing the initiation of the next spike. 
		The neuron's depolarization is reset to $v_r < \tau$ after a spike, meaning that the considered variable goes through a net rising phase in the course of an inter--spike interval. 

		A rising phase means that earlier values are smaller than the current value.
		Equation \ref{eqLeakageForLIF} shows that leakage is proportional to the depolarization value, and that the previous value is utilized for computing the current leakage.
		The simulated leakage in $NIM$ thus generally produces a positive depolarization error, i.e. it causes the depolarization value to be larger than it should be.
		In the course of an inter--spike interval, all local truncation errors caused by this effect are integrated to what will be referred to as the inter--spike truncation error.
		When utilizing the sample--and--hold integrated technique, this error is predictable and always causes the neuron to fire to early.
%% 		%%
		An early firing gives an earlier start of the next inter--spike interval, meaning that the neuron's depolarization is integrated over an interval that is too long. %for a too long interval.
		In most cases, this further increases the positive depolarization error and is the background of the cumulative property of the $NIM$ error.

	
		An opposite error comes as a direct consequence of having discrete time.
		The \emph{action potential} is defined to happen when the depolarization crosses the firing threshold from below.
		To preserve causality in a network of artificial neurons, the \emph{action potential} has to be delayed to the time step after the threshold crossing.
		% TODO Skriv om forsøka som er gjort med å ha mindre time steps inni kvart computational time step. Lest det i en artikkel, en gang.. (ALL Citing er BRA CITING!)
		This introduces a small delay before firing, causing a delayed transmission and a delayed initiation of the subsequent inter--spike interval.
		As previously described, this gives an initial depolarization error for that inter--spike interval.
		The error from having discrete possible firing times has the opposite effect of the inter--spike truncation error. %, and gives a negativ error for the neuron's depolarization.


 		The net inter--spike simulation error is defined by the relative size of these mechanisms.
		The error from having an erroneous leakage varies from having a size of $e_l=0$, if the neuron uses an eternity to reach the firing threshold,
%		The error from an erroneous leakage caused by the discretization of time varies from having a size of $e_l=0$ if the neuron uses an eternity to reach the firing threshold,
			 to the size of the correct leakage if the depolarization goes all the way from $v_r$ to $\tau$ in one iteration.
		The error caused by having discrete possible firing times varies from $e_d=0$, if the threshold crossing happens at the very end of the time step,
			to having a magnitude defined by the size of one full computational time step if the threshold crossing happens immediately after the initiation of that time step.
		The derivative of the accumulated truncation error(the change in global truncation error) is therefore hard to predict and supress. %control. %avoid.
		Since the global truncation error in $NIM$ is defined by the integral of all previous depolarization errors, 
			any systematic local error causes the global truncation error to diverge for $t\to\infty$.
			%any systematic local error (with an expectancy value different from zero) causes the global truncation error to diverge for $t\to\infty$.
	



		\subsubsection{Algebraic Simulation Model($\kappa M$)} %Eller noke..

		In $\kappa M$, the considered variable is the \emph{synaptic flow} of activation level, visualized as a stream in the gutter analogy in sec. \ref{secDevelopmentOfTheNovelANNmodel}.
		This flow varies as a continuous function within a bounded domain, and does not have a net rising phase during each inter--spike interval.
		The flow of activation level is invariant of time, and a delayed computation of the neuron's activation level only delays its response.
		Thus, the $\kappa M$ error is bounded and varies as a function of the derivative of the neuron's input flow.


		If the $\kappa M$ simulator is implemented with intra--iteration time accuracy (see section \ref{ssecTheActionPotential}), the next inter--spike interval can be initiated at the computed time instance.
		If all tasks are executed according to estimated spike times, a task planned slightly before another will be initiated before that task. %, despite being scheduled in the same computational time step.
%%
		This effect is only limited by the data format used, and a double precision floating point variable is utilized in $auroSim$.
		The IEEE standard defines the smallest exponent of this data format to be $-308$, giving an accuracy where two numbers can be separated by steps down to $10^{-308}$ \cite{kreyszig8edKAP17}.
		This makes it possible to have almost infinitesimal sizes for the delay meant to assure causality, and the next inter--spike interval can be initiated immediately.
		In this way, also the second discussed error mechanism of $NIM$ is avoided in $\kappa M$.
% 		Thus, also the second discussed cumulative error mechanism of a $NIM$ simulation is avoided in $\kappa M$.
		Because the $\kappa M$ error only comes from the delayed update of a bounded variable, the error varies within a bounded domain. %, something that will be referred to as the stability property of the $\kappa M$ error.
 		This will be referred to as the stability property of the $\kappa M$ error.


%	
%------ Tatt ut av "The Action Potential" asdf@jeje12
%------ Tatt ut av "The Action Potential" asdf@jeje12
%
%	If e.g. the double precision floating point format is utilized, the IEEE standard defines the smallest number to be given by an exponent of $-308$, %\cite{kreyszig8edKAP17},
%		giving an accuracy where two numbers are separated by steps down to $10^{-308}$ time units\cite{kreyszig8edKAP17}.
	%For e.g. the double precision floating point format, the IEEE standard defines the smallest number to be given by an exponent of $-308$\cite{kreyszig8edKAP17}. 
	%This implies an accuracy where the numbers are separated by a step down to $10^{-308}$ time units.
	%For a discussion about what this results in for the simulation error, it is referred to sec. \ref{ssecAnalysisOfErrorsForTheTwoModels}.
	%This will have a large effect on mechanisms defined by the relative spike times of two neurons, e.g. Spike--Time Dependent Plasticity as mentioned in appendix \ref{appendixSynapticPlasticity:postsynapticMechanisms}. 
%
%
%		Probably the most important effect of having near--continuous temporal resolution with respect to the simulation error is therefore that the next inter--spike interval can be initiated at the right time. %computed time instant.
%	After an action potential(and the predefined absolute refraction period), the neuron can start charging the membrane potential without delay. %at the right time. %computed time instant.  
																																				%removing the second discussed error mechanisms in the NIM

