
%  		- Skriv om at med dEstimatedTaskTime-opplegget er det ikkje nødvendig å simulere spatiotemporal delay. I aksonet for eksempel. Dette er kjempebra for neuronsimulering.
% 			- Mulighet for "multi-compartment model with single compartment implementation".
% 		
% 		- Skriv om at det var teit å bruke deriverte ved overføringer. Bedre ville det vore å bare definert det slik at kvart neuron oppdaterte(rekalkulerte) kvar iterasjon. 
%
% 		- Directions for further work


%TODO Bruk: 	"This study shows ..." 	Veldig rett formulering! XXX


%XXX skrive om Lovelace and Cios(2008) som "proposed a very simple spiking neuron(VSSN) model, og "Simplicity an Efficiency of Integrate--and-fire neuron models" mener er drit. Denne bruker en forenkling av SANN, men diesmann og Plesser mener den er dårlig. Skriv om at eg går motsatt retning, og bruker meir avanserte metoder for å finne meir correct resultat(som betyr meir effektiv simulering).



% TODO Synaptisk plasticity! Kan bruke både aktivitetsbasert og spikebasert!   TODO 



\section{Summary}

The mechanisms of biological neuron networks, the computational system of biological beings, is not fully understood.
% How biological neural networks, the computational system of biological beings, function is not fully understood.
On a low level, neuroscientists have found that networks of neurons propagate information by discrete action potentials.
An action potential causes a transmission through all the neuron's output synapses, leading to the increase or decrease in the postsynaptic neuron's value.
This value, referred  to as \emph{the depolarization} of the neuron, is the result of a leaky integration of synaptic input transmissions.
% This value, referred to as \emph{depolarization}, can be considered to be the result of a leaky integration of synaptic input transmissions.
% This value, referred to as \emph{depolarization}, can be seen as a leaky integration of synaptic input transmissions.

Digital simulations have discrete time, and a neuron's depolarization is often simulated by numerical integration.
%Digital simulations have discrete time, and continuous mechanisms like leakage can be simulated by numerical integration.
This is done by adding synaptic input and subtracting an estimate of the neuron's leakage.
In this work, the previous time step's value is utilized when computing leakage for the $NIM$ model (\emph{sample--and--hold integration}). % in the implementation that utilizes numerical integration

This study shows that the error from each computational time step varies like a stochastic variable, and that the total error is defined as the integral of all local errors. 
This results in a diverging simulation error, unless the local truncation error has an expectancy value of zero.
In an attempt to avoid this, a novel simulation scheme has been developed that does not involve numerical integration.
% In order to avoid this, ideas from systems theory have been utilized to develop a new simulation scheme that does not depend on numerical integration.
Using the concept of \emph{time windows}, time intervals where the neuron's depolarizing inflow is held constant, a neural simulator was developed that utilize the algebraic value equation in these intervals.
% By the concept of \emph{time windows}, time intervals where the neuron's depolarizing inflow is held constant, a neural simulator was developed that utilize the algebraic value equation in these intervals.
% %%%%
Software intended to make differences in design of the two simulation schemes have been designed and implemented, $auroSim$.
The artificial neuron has the functional lay--out of the biological neuron, with four distinct subelement types, [$i\_dendrite$, $i\_auron$, $i\_axon$, $i\_synapse$].
The abstract \emph{i\_\{element\}} types are inherited to \emph{s\_\{element\}} and \emph{K\_\{element\}}, model specific classes.
All common aspects between the two simulation models can thus be placed in the ancestor \emph{i\_\{element\}} class, making principal differences in design of the two simulation schemes prominent.

It is shown experimentally that although the $\kappa M$ simulation scheme is computationally more complex, the simulation is more effective. %it gives a more effective simulation.
Because the $\kappa M$ simulation scheme produces less errors, longer computational time steps can be used to achieve the same accuracy.
This makes it possible to utilize fewer computational time steps to achieve the same degree of simulator accuracy, enabling a more effective simulation.
It is also shown that the absolute error of the algebraic simulation scheme is bounded, something that could be of importance in complex ANN simulations.
% It is also shown that the algebraic simulation scheme has a bounded error, something that might be important in complex ANN simulations.


%XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX 
% \section{Contribution of Thesis}
% 	-modell
% 	-simulation scheme
% 	-implications of results
% 	-future directions


\section{Discussion}  
	One question that presents itself is the importance of a gradually increasing cumulative error.
	The most immediate errors are the ones that alter the length of an inter--spike interval.
	These are represented as the derivative of the spike--time error curves in fig. \ref{figSpikeTimeErrorExperiment2}; % or \ref{figExperiment2ErrorInTenSineOscillations};
		when an inter--spike interval has an erroneous length, the spike--time error is changed by this amount.
	Fig. \ref{figSpikeTimeErrorExperiment2} shows that in the first period of the forcing function, the $\kappa M_{100}$ spike--time error change with about the same rate as the $NIM_{1.000}$ error.
	After spike nr. $20$, the derivative of the spike--time error is larger in the $NIM_{1.000}$ simulation than in the $\kappa M_{100}$ simulation.
	This illustrates a significant efficiency improvement, as the $NIM$ simulation has a temporal resolution that involves ten times as many time steps as the $\kappa M$ simulation.
% 	The $NIM$ simulation has a temporal resolution that involves ten times as many time steps, and illustrates a significant efficiency improvement by utilizing the $\kappa M$ simulation model.
% 	Since the $NIM$ simulation have a temporal resolution that involves ten times as many time steps as the $\kappa M$ simulation, this illustrates a significant efficiency improvement for the novel model.
% 	Since the $NIM$ simulation has ten times as many time steps, this shows a significant efficiency improvement when utilizing the $\kappa M$ simulation model.

	Fig. \ref{figExperiment2ErrorInTenSineOscillations} shows the spike time errors for the same experiment, simulated over a longer time interval. 
%	Fig. \ref{figExperiment2ErrorInTenSineOscillations} shows the spike time error in an artificial neuron simulated over a longer time interval.
	One can observe the cumulative property of the $NIM$ error as a gradual increase in the absolute spike--time error. %, over the duration of the experiment. 
%	One can observe the cumulative property of the $NIM$ error, since the absolute spike--time error increases over the duration of the experiment. 
% XXX Remove the next two sentences? XXX
% 	Also note that the rate of change, represented by the magnitude of the oscillations in the spike--time error, increases in the course of the experiment.
% 	The reason for this is unknown. %xxx Ta med? This is important for discussion! TODO
%%%
	To compare the $\kappa M_{100}$ simulation's spike--time error with the $NIM_{10.000}$ simulation's error, the difference in absolute error is presented in fig. \ref{appendixDifferenceInErrorFig}.
	This figure shows that in the second half of the experiment, the $\kappa M_{100}$ error is generally less than the $NIM_{10.000}$ simulation's error. %for the $NIM_{10.000}$ simulation.
	This implies an even greater efficiency improvement, as the $NIM$ simulation has a number of time steps that is two orders of magnitude larger than the $\kappa M$ simulation's.
	In all conducted experiments, this effect becomes larger for longer simulations.
% 	It appears that this effect becomes larger for longer simulations.

	Reproducibility has been an important element in the conducted experiments in this work.
% 	In the experiments conducted in this work, reproducibility of results have been in focus.
%%%	The design of the comparison software, and the implementation of fundamental simulation elements have therefore been documented in this text.
	The most important elements of the simulation software are well documented, and the forcing functions in the experiments are represented by algebraic functions.
% 	The forcing functions in the conducted experiments are represented as algebraic functions.
% 	The forcing functions are therefore represented as algebraic functions.
	It is possible that the use of algebraic forcing functions limits the validity of the results, since the input to a node in a neural network is far from being a smooth algebraic function.
	Experiment 2 considers a sinusoidal forcing function, where neither the value nor the derivative is constant for any time interval. % at any time.
	This can be used as a basis in a Fourier series to produce any periodic signal.
	This forcing function can therefore be seen as a component in any signal, and is considered to be an appropriate algebraic function for efficiency measurements. %be a good signal for efficiency mesurements.
	A stochastic Wiener process could also be used, but this would make the experiments harder to validate for others.
% 	
% 	The use of algebraic input functions makes reproduction of the results simpler, but might be a limitation for the validity of the results.
%%
	To simplify further analysis and for a thorough study of the implementation, $auroSim$ has been published under \emph{GPL}.
%	To simplify further analysis and for a thorough study of the conducted experiments, $auroSim$ has been published under \emph{GPL}.
	The source code can be found under branch \emph{master} in the git repository located at \emph{https://github.com/leikanger/masterProject} \cite{gitRepoCommit}.


	One element that could be worth examining, is the ability of the $\kappa M$ simulation model to simulate the neuron by other formal neuron models.
% 	Something that could be worth examining is the ability of $\kappa M$ to simulate the neuron by other formal neuron models.
	The $LIF$ neuron model is often used because it is simple, and does not involve complex operations.
	Other neuron models are reported to produce more accurate simulation results \cite{gerstnerKistler2002}. %\cite{gerstnerKistler2002KAP04}.
% 	Some other neuron models are reported to give more accurate simulation results\cite{gerstnerKistler2002}.
% 	Other formal neuron models is reported to give more accurate simulation results\cite{gerstnerKistler2002}.
	The $\kappa M$ simulation scheme is thought to be applicable for any neuron model where the depolarization is described by an ordinary differential equation.
	As long as the value equation is defined as a function of a single variable, \emph{time windows} can be defined, and the $\kappa M$ simulation model can be utilized.
	The use of $\kappa M$ for systems defined by partial differential equations or sets of ordinary differential equations, is also an area that could be worth examining.
% 	These models can probably be simulated with $\kappa M$ by substituting the $LIF$ neuron's equation with the alternative model's value equation. %, in the implementation.
	%These models can be simulated by substituting the $LIF$ neuron's value equation with the alternative model's equation. %, in the implementation.
% 	It is probable that a $\kappa M$ simulation of these models is as precise as for the $LIF$ model, enabling equally effective simulations of these neuron models.
% 	This can be done by substituting the $LIF$ neuron's depolarization equation with an other neuron model's in the implementation.

	When edge transmission is implemented as the derivative of synaptic flow, transmissions are only needed when there is an altered activation level for the presynaptic neuron.
% 	When edge transmissions as the derivative is implemented, transmissions are only needed when there is an altered activation level for the presynaptic neuron.
% 	Edge transmissions as the derivative enables the synapse to transmit, only when there is an altered activation level for the presynaptic neuron.
%	Edge transmissions as the derivative enables the synapse to transmit, only when the presynaptic neuron has an altered activation level.
% 	Edge transmissions as the derivative enables the synapse to conduct transmissions only when the presynaptic node has an altered activation level.
% 	The use of edge transmissions as the derivative, causes transmissions to be needed, only when the presynaptic node has an altered action level.
% 	The use of edge transmissions as the derivative seemed like a good idea, since transmissions are only needed when the presynaptic node has an altered activation level.
	When a double precision floating point data type is used, with the smallest increase defined to be $10^{-308}$, it is highly unlikely that the activation level of a node remains constant over any time interval.
% 	Because a double precision floating point data type is used, with a precision down to $10^{-308}$, it is highly unlikely that the activation level of a node is constant over a time step.
	The concept of edge transmission as the derivative does not decrease the efficiency of a simulation, but it does not improve it either.
% 	The concept of edge transmission as the derivative therefore does not improve efficiency noticeably.
	It does increase the complexity of the design/implementation, and is recommended to be removed for further uses of $auroSim$.
%%%% Ta med? Ta vekk? ???
% 	Because it does not affect the simulation results, or other comparisons in this report, edge transmission for the nodes has not been altered
%	Because it does not affect the simulation results or other comparisons in this report, edge transmission as the derivative has not been altered in this work.
	
	%todo todo todo todo todo todo todo todo todo todo Skriv om bruk av andre integrasjonsmodeller: Burde sjekka f.eks. runkegutta' todo todo todo todo todo todo todo todo todo todo 


% 	Why the oscillations in spike--time error grows in longer $NIM$ simulations is unknown.
% 	- Muligheten for å bruke KM for andre neuron-models. Skriv at så lenge man har en algebraisk funksjon kan KM brukes. Får en 'bounded error'.
% 	- Mulighet for å interface'e med 2.gen. ANN og andre filter. (skrevet dette før?) Sjekk, og evt. skriv her..
	


\section{Conclusion}
	%TODO Konsklusjon: NIM error auker mens KM error er stabil. Som forutsett..

	This work introduces an entirely new way of considering a neuron's activation level.
	The novel formalism considers what the neuron's depolarization would approach, $\kappa$, if no firing interrupts it.
	The $\kappa$--formalism enables the use of algebra to find the neuron's depolarization, as well as the immediate firing frequency of the neuron.
	Combined with the concept of \emph{time windows}, time intervals where the depolarizing inflow is held constant, spiking neuron simulations can be conducted without the use of numerical integration.
% 	Combined with the concept of \emph{time windows}, it is possible to conduct a spiking neuron simulation that does not utilize numerical integration.



	The traditional Numerical Integration Model($NIM$) and $\kappa M$ is compared theoretically and experimentally in this report. % analitically in this report.
%	Section \ref{ssecAnalysisOfErrorsForTheTwoModels} shows that because the neuron has a positive 
	The analysis of the $NIM$ model shows that the local truncation error has stochastic elements, and that the global truncation error diverges unless the local errors have a expectancy value $\hat{e} = 0$. %that is zero.
	The $\kappa M$ error is a result of a delayed update from a variable that varies within a bounded domain, producing a bounded error. % causing the error to be limited.

% 	The neuron has a potential unlimited increase in depolarization value, since this value has a positive increase till the firing threshold before being reset, every inter--spike interval.
% 	This happens every inter--spike interval, causing a potentially unlimited increase in value. %(positive derivative).
% 	Any systematic local truncation error based on this value therefore produce a diverging error for the simulated depolarization. % neuron's depolarization.

	The two simulation models were implemented in a common framework, and accuracy comparisons was conducted. % on the resulting software.
	These comparisons are relevant since the differences between the models were isolated and potential faults in the common framework affects both models equally.
%FORRIGE(amund endra foreslår å endre. Dette prøver eg å gjør, over) GAMML:	Accuracy comparisons thus give more valid results, as the differences between the models were isolated and potential faults in the implementation of a simulator affects both simulations.
%	Accuracy comparisons thus give more valid results, as the differences between the models were isolated and other implementation details are shared.
%% Ta med? Ta vekk?
% 	The time course of the simulated neuron's depolarization has been compared to a high--resolution simulation to find the two models' error.
	It is shown that in the course of $15$ periods  of a sinusoidal forcing function, the $\kappa M_{100}$ simulation, a $\kappa M$ simulation with $100$ time steps per forcing function period,
		generally produces more accurate results than a $NIM_{10.000}$ simulation.
% 		produces more accurate results than a $NIM_{10.000}$ simulation.
	This is a significant efficiency improvement, as the $NIM_{10.000}$ simulation has a number of time steps that is two orders of magnitude larger than for the $\kappa M_{100}$ simulation.
	All results imply that this effect becomes larger for longer simulations, making the $\kappa M$ simulation model a significant improvement of today's spiking neuron simulation model.

%	
%1	Experiments conducted on the resulting software, $auroSim$, implies that the conducted error analysis is accurate.
%1	The $NIM$ simulations have an accumulation of error, while the $\kappa M$ simulations have a bounded error.
%1	In only $15$ periods of the sinusoidal forcing function, it is shown that the $\kappa M_{100}$, a $\kappa M$ simulation with $100$ time steps per sinus period, 
%1		produce a more accurate result than a $NIM_{10.000}$ simulation.
%1	This implies a significant efficiency improvement, as the $NIM_{10.000}$ simulation has a number of time steps that is two orders of magnitude larger than the $\kappa M_{100}$ simulation.
%1	All results implies that this effect grow larger for longer simulations.


% //{ KOMMENTERT UT!
% \chapter{UFERDIG.. kladd:}
% 
% 	If for example all inter--spike intervals are increased by the same factor, one can say that this is a similarity transform of 
% 		the real inter--spike intervals. % and the results can be transformed back.
% 	For ``offline simulations'' with e.g. scientific intent, the resulting depolarization and spike times can thus be transformed back.
% 	If the emulator is to be used for real--time applications, it is hard to avoid that the transformed results are utilized instead of the correct values.
% 	The gradually increasing spike time error affects the activity level of the neuron, altering the mean firing frequency of the neuron;
% 		When the firing time error increase by some factor $C_{e}$ in the course of the interval $\Delta t$, 
% 		the resulting firing frequency error for that interval have a magnitude $e_f = \frac{C_e}{\Delta t}$.
% 
% 	\begin{itemize}
% 		\item[-] Årsak til at feilen er mindre for KANN: intra--iteration time accuracy, use of algebraic function, 
% 		\item[-] Bruk av edge transmission: Kvifor er dette bortkasta arbeid? Skriv også at det BARE auker kompleksiteten på implementasjonen.
% 		\item[-] Limitations: bruk av algebraisk test-funk. Kanskje dette gjør eksperimentet ubra? Snakk om Fourier-series som lineærkombinasjon av sinusoidal functions.
% 		\item[-] Sammenligning: burde kanskje også sammenligna med en etablert software, som NEURON eller [det fra ås]. Dette ville gjort resultata av effektivitetsanalysen meir overbevisandes.
% 				\emph{vart ikkje gjort fordi dette ikkje var hovudelemented i prosjektet}.
% 		\item[-] Burde sjekka meir avanserte integrasjonsmetoder for NIM.
% 		\item[-] Task-scheduler: muliggjør meir effektiv simulering av spatio-temporal effects.
% 		\item[-] Diskuter kvifor oscillations in the error increase for longer simulations.
% %Diskuter litt om kvifor oscillations i feilen auker, for SANN. Kaffaen er dette? Det ser ut som om feilen svinger meir(deriverte er større) etterkvart, for SANN. Dermed er det ikkje bare den absolutte feilen som auker, men også svingningene av feilen..
% 		\item[-] 
% 	\end{itemize}
% %By considering the neuron's activation level by the value the depolarization would approach in the absence of a firing threshold, 
% 	
% 	\
% 	\subsection{Limitations}
% 	\subsection{Implications of Results}
% 
% 	
% \section{gammel discussion}
% 
% As the neuron fires when the value crosses the firing threshold and an algebraic equation is utilized to find the depolarization value,
% 	the exact firing time $t^{(f)}$ can be estimated by the equation $v(t^{(f)}) = \tau$. 
% 	%the exact firing time can be estimated by an equation that equals the algebraic formula to the firing threshold. %TODO Skriv litt om på slutten.
% The $\kappa$ formalism can be used to simulate the neuron by utilizing the concept of 'time windows', intervals where $\kappa$ is constant.
% A changed $\kappa$ initializes a new time window, and the initial value for the value equation is found as the last value in the previous time window.
% %A changed $\kappa$ initializes a new time window, and the firing time estimate needs to be updated.
% Time windows are thus fundamental for the use of the $\kappa$ formalism in a neural simulator.
% %When a new time window is initialized, the depolarization value and firing time estimate is updated for the neuron.
% 
% % TODO TA vekk: Dette er ikkje en diskurs!
% % When a new time window is initialized, the depolarization value and a new firing time estimate is computed.
% % %When $\kappa$ is updated, the depolarization value of this time is computed and saved along the time of initiation of the new time window.
% % The computation of a new firing time estimate and all other aspects involved in initiating a new time window are only computed once, 
% % 	at the end of a computational time step.
% % This saves much computational resources, and cause these computations to be executed as often as the computations of leakage in $NIM$.
% % The computational complexity still makes the $\kappa M$ simulation more demanding on the system, and the per--iteration efficiency is lower than for the $NIM$ model.
% % %It also generates a smaller error OR SOMETHING..
%  
% 
% 
% Two experiment have been set up to assess the discussed theory.
% The first experiment considers a constant depolarizing inflow, and illustrates that the $\kappa$ formalism can be used to simulate the depolarization of the neuron. 
% The $\kappa M_{100}$ simulation produce the algebraically correct spike times for all spikes, 
% 	indicating that the $\kappa M$ error analysis varies with the change in activation level.
% As the $NIM_{100}$ simulation produce a cumulative error of notable size, the first experiment justifies the conclutions from the theoretical error analysis in sec. \ref{ssecAnalysisOfErrorsForTheTwoModels}.
% 
% 
% The second experiment considers a single sensory neuron with a forcing function given by one and a half period of a sine function. %TODO sine?
% This study shows that errors of approximately the same magnitude is achieved for a $\kappa M_{100}$ simulation with a temporal resolution 
% 	of $100$ time steps per sensory function period as a $NIM_{1.000}$ simulation with ten times the number of time steps.
% The results also indicate that the $NIM$ simulation produce a cumulative error, while the $\kappa M$ simulation have 
% 	an error that only varies with the phase of the forcing function.
% To test the extend of the hypothesized cumulation of error for $NIM$, % and the stability property of the $\kappa M$ error,
% 	the experiment was repeated with a simulation time interval that is ten times as long.
% The cumulative property of $NIM$ is prominent, and the results also verifies the hypothesized stability property of the $\kappa M$ error;
% 	Instead of having an accumulation of truncation errors from numerical integration, $\kappa M$ error varies within constant bounds. %a constant interval. 
% An error from a delayed update can also possibly be dampened by methods from systems theory or numerical estimation.
%  	
% 
% %%% XXX HAR FLYTTET OPP...
% 	One question that presents itself is the importance of a gradually increasing cumulative error.
% 	%One question that presents itself is the importance of a gradually increasing accumulation of error.
% 	If for example all inter--spike intervals are increased by the same factor, one can say that this is a similarity transform of 
% 		the real inter--spike intervals. % and the results can be transformed back.
% 	For ``offline simulations'' with e.g. scientific intent, the resulting depolarization and spike times can thus be transformed back.
% 	%For simulations with a scientific intent, the resulting depolarization and spike times can thus possibly be transformed back.
% 	If the emulator is to be used for real--time applications, it is hard to avoid that the transformed results are utilized instead of the correct values.
% 	%This is hard if the emulator is to be used for real--time applications.
% %
% %	Problems arise when this is to be used for real time applications;
% %		Unless the simulation results are transformed back, the transformed results are utilized instead of the correct values.
% %	Transforming the results back demands algebraic equations for the error, and is hard to achieve for $NIM$ simulations.
% %%%%%%%%
% %	Another problem with having a gradually increasing error is that the mean firing frequency is affected by this gradual increase in absolute error.
% %	If the firing time error increase by some factor $C$ in the course of the interval $\Delta t$, 
% %		the resulting firing frequency error for that interval have a size $e_f = \frac{C}{\Delta t}$.
% %	%The implications of errors are therefore hard to predict in a complex neural network.
% %	%If there is a motivation for doing accurate simulations with a maximal error, the $\kappa M$ simulation scheme is a contribution to the field of computational neuroscience	and/or neural--inspired  cybernetics.
% %%%%%
% %%  %%
% 	%If there is a gradually increasing error, the mean firing frequency of the neuron is affected.
% 	The gradually increasing spike time error affects the activity level of the neuron, altering the mean firing frequency of the neuron;
% 		When the firing time error increase by some factor $C_{e}$ in the course of the interval $\Delta t$, 
% 		the resulting firing frequency error for that interval have a magnitude $e_f = \frac{C_e}{\Delta t}$.
% 	%If it is important that the neuron simulations are accurate without a gradual increase in error,
% 	%	the $\kappa M$ simulation scheme accomplish a small and limited absolute error at a relatively low computational cost.
% %%%
% 	
% 
% The concept of edge transmission, where the signal is propagated as the derivative of synaptic transmission seems like a good idea.
% Only the subset of input synapses with a changed transmission level is considered by the postsynaptic node.
% % Because floating point precision is utilized for representing $\kappa$, 
% % 	it is highly unlikely that the activation level remains constant to this resolution.
% % The concept of edge transmission increase the complexity of the design, and it is recommended that information is propagated as 
% % 	synaptic flow instead of its derivative.
% When $\kappa$ is represented with a floating point precision, it is unlikely that the activation level remains constant 
% 	to this accuracy from one computational time step to the next.
% The concept of edge transmission as the derivative thus only increase the complexity of the design, without impoving simulator efficiency.
% %The concept of edge transmission as the derivative therefore does not involve any efficiency improvement, and only increases the complexity of the design.
% It is therefore recommended that information propagation is implemented as synaptic flow instead of its derivative in future work.
% % It is highly unlikely that the activation level remains constant to the resolution of the floating point data format,
% % 	the consept of edge transmission as the derivative therefore does not involve any efficiency improvement.
% % Transmission as the derivative therefore only increase the complexity of the design, and it is recommended that information is propagated
% % 	as synaptic flow instead of its derivative.
% 
% 
% 	%TODO TODO Diskuter det med umiddelbar vs. transient-kurve for overføring! Kanskje KM er bedre for dette? (bruker ikkje dirac-delta)
% 
% \section{Limitations}
% 	%Her kan eg DISKUTERE begrensninger med dette arbeidet(diskutere frem og tilbake. Kanskje ende opp positivt?
% 	%VELDIG bra for å få full score på kor reflektert arbeidet er!
% 
% 	%\subsection{The Model} xxx
% 		%The $\kappa M$ simulation scheme is possible after a couple of simple concepts woven together to make is possible to utilize the algebraic equation for the neuron's depolarization.
% 		%Because the simulation model utilize the algebraic solution to the $LIF$ neuron's differential equations, the author can only think of two aspects that can be limiting for the $\kappa M$ simulation model.
% 		The concept of 'time windows' makes it possible to utilized algebraic equations to simulate the depolarization of the neuron.
% 		The model used in this work is the $LIF$ neuron model.
% 		This is a simple neuron model with many abstractions, and gives less correct simulation results than more advanced models\cite{CITE}.
% 		It is still used in this work, as this model is the most commonly used neuron model in computational neuroscience\cite{CITE}.
% 
% %%TODO Skriv 
% %%TODO [leikanger] hevder at sånnOgSånn, difor har eg brukts Sånn.. 		Hevder at, raporterer at, sier at, har gjort, ...
% 
% 		[CITEAUTHOR] reports that e.g. the nonlinear IF model is a more precise and balanced neuron model\cite{CITE}.
% 		It is likely that all models that can be represented by a funtion of a single variable can be simulated by the novel simulation scheme. %$\kappa M$.
% %		In this case, the alternating model's equation for depolarization is used instead of that of the $LIF$ model.
% 		%The alternating model's equation for depolarization have to be used instead of that of the $LIF$ model.
% 		%The algebraic solution to the $LIF$ model only has to be substituted with the equation for the alternative model.
% %		As these models are harder to simulate numerically, it is believed that the efficiency improvement could be even larger for these models. 	%%%
% 		This is something that aught to be tested.		
% 
% %		%The nonlinear IF model have not been examined, but could be especially [EGNET]suited for simulation by the $\kappa M$.
% %		%[SKRIVE MEIR OM DETTE]
% %		%The nonlinear integrate--and--fire model have not been examined, but the native use of the exponential function in $\kappa M$ makes
% %		%	it probable that $\kappa M$ can be relatively computationally more effective than a $NIM$ design.
% %		This might be the case for other neuron models as well, and is worth further examination.
% 
% 		An other aspect that might be a limitation for the $\kappa M$ implementation, is how synaptic transmission is modelled.
% 		Because $\kappa M$ propagates information as a second generation ANN, with transmission of the activation level, 
% 			it is hard to imagine whether all aspects of the propagation of spikes are preserved.
% 		With the $NIM$ design, synaptic transmission can e.g. be implemented as transient transmission curves instead of instantaneous transmissions.
% 		It is possible that this is possible for $\kappa M$ as well, by letting $\kappa_{ij}$ have a transient curve.
% 		%It is possible that $\kappa M$ also makes this possible, by letting $\kappa_{ij}$ have a transient curve.
% 		It is therefore recommended that this aspect is examined further.
% 
% %		The third aspect comes from the implementation and computational complexity of the $\kappa M$ simulation scheme.
% 
% %	\begin{itemize}
% %		\item Bruk av $LIF$ modellen:
% %			\begin{itemize}
% %				\item [-] ikkje så bra modell
% %				\item [+] mest brukte modellen
% %			\end{itemize}
% %		\item Diskuter korleis KM kan utvides for f.eks. nonlinear model.
% %			\small{KM kan gjøre det lettare å bruke transiente overføringskurver(enn dirac delta)}
% %		\item Synaptisk plasticity
% %	\end{itemize}
% %		\subsubsection{Further Work (-ikkje med, men viktig å hugse-)}
% 
% 	%\subsection{The Implementation} xxx
% 		An important focus for the experiments conducted in this work have been to make it simpler to verify the results.
% 		%An important focus in the experiments conducted in this work have been on reproducibility.
% 		The source code is therefore freely available\cite{gitRepoCommit} and all experiments have been conducted with an algebraic forcing function.
% 		It is thus simple to examine the source code and verify the results, as well as examine other elements/situations.
% 		%It is thus possible to examine the source code and reproduce the results as well as further examine other elements.
% 		Other sensory functions can be examined by declaring them in the file \emph{sensoryFuntions.h} 
% 			and constructing sensory aurons with the pointer to that function as argument.
% 		% All experiments have been conducted with an algebraic forcing function and with a focus on making it possible for others to reproduce the results. 
% 
% % //{ KOMMENTERT UT
% %	This work [OMFATTER] two different projects.
% %	The first, and in the beginning the most important project, have been to compare the two $LIF$ neuron simulation schemes.
% %	Both simulators have been implemented from scratch, in order to emphasize the differences between the two models.
% %	%Both simulators was implemented from scratch, to be able to see important differences between the two models.
% %	
% %	The second part of the report that considers the efficiency comparison between $\kappa M$ and $NIM$, % the two simulation models, 
% %		and utilize the resulting simulator software from the first part.
% %	%The second part of the project, involving efficiency comparison between the two models used this implementation when comparing $\kappa M$ and $NIM$.
% %	Both implementations have nodes that are designed as the biological neuron, with four subelements representing the functionality
% %		of [dendrite, soma, axon, synapse].
% %	%Both implementations are designed as a biological neural system, with four sub--compartment in each node.
% %	It can thus be said that both models are designed so that spatiotemporal delay is simulated directly in the artificial neuron.
% %			% as a direct simulation of the biological neuron.
% %%% 	%%	  %%%
% %	It is found that this is not necessary, and only introduce more computational load for the simulation.
% %	Because the task scheduler can be utilized for both neural simulation models, this has not been persuaded any further in the efficiency comparison. %XXX persuaded? Sjekk om dette er feil skrivemåte.. (forfulgt..)
% %	It is possible that implementing the task scheduler for the $NIM$ simulation model introduce more computational load, but it is unlikely that this is more demanding than simulating intracellular signal propagation.
% %	%Delay can instead be implemented by scheduling tasks to happen after the defined delay, and no more computational resources have to be used.
% %	As the efficiency improvement from utilizing the task scheduler only affects the run time and not the results,
% %		utilizing the task scheduler would not affect the simulation results.
% %	The efficiency comparison done in this work would therefore be unaffected by doing this.
% %%the result of a comparison that only considers the accuracy of the simulation results.
% %	It is still recommended that further development of $auroSim$ utilize the task scheduler developed in this work%
% %	(the source code of $auroSim$ can be found at \cite{gitRepoCommit}).
% %	%(for the source code of $auroSim$, if is referred to \cite{gitRepoCommit}).
% %	%It is still recommended that future uses of $auroSim$ utilize the task scheduler developed in this work.
% %	%This would only affect the total run time of the simulation, not the accuracy of the simulation results.
% %
% %	%It is also believed that a multiple--compartment model can be simulated in a single--compartment implementation.
% %	%This is an important direction for further work, as it can greatly improve the efficiency of scientific simulations utilizing multiple--compartment models of the neuron.
% %	
% %	%An other aspect that makes the $\kappa M$ implementation more complex is the use of edge transmission as the derivative.
% %	%TODO Skrive om dette?
% %
% %%TODO Ha med, eller ikkje? XXX:
% %%	The results from the efficiency comparison might have been more credible if an established simulation software was used for the $NIM$ simulation.
% %%	%The best approach, when comparing the efficiency of the two models could be to use established software for the $NIM$ simulation.
% %%	As both implementations are designed and written by the author, the $NIM$ implementation can be criticized for being 
% %%		less accurate than other $NIM$ implementations.
% %%	The approach where both simulation models are implemented from a common framework have still been utilized, 
% %%		to minimize the effect of errors originating from the common framework on the comparison. %on the results.
% %%		%as errors originating from the common framework thus affects both simulation models equally.
% %%	%As both simulation models are implemented in a common framework, and it has been important that all common aspects between the
% %%	%	two models are similar, this approach have still been utilized.
% %%	This causes suboptimal elements from the framework to affect both models, and the two models have a more equal [UTG.PKT].
% %%	%It is believed that all elements that are sub--optimal affects both models equally.
% %
% %
% %%	The efficiency comparison done in this work considers the error from $\kappa M$ and $NIM$ simulations.
% %%	The results from a $NIM$ simulation with a temporal resolution that is two orders of magnitude larger than for the compared simulations is used as the correct time course for the neuron's depolarization.
% %%	%The results that are used as the correct time course for the neuron's depolarization is found by a $NIM$ simulation with a number of time steps that is two orders of magnitude larger than the compared simulations.
% %%	%This approach to finding the correct value is validated, as it is shown that the truncation error is proportional to the size of the computational time step.
% %%	The node is designed to emulate a sensory neuron, where the change in depolarization varies with the sensed signal, enabling algebraic 
% %%		functions to define each experiment.
% %	//}
% 
% %	Algebraic input functions are chosen to make the experiments replicable.
% 	By an infinite sum of different sine functions with different phase and frequency, any signal can be modelled exactly\cite{CITE}.
% 	The forcing function utilized when assessing efficiency is therefore chosen to be a sine function.
% 	%The forcing function utilized when assessing efficiency have been used as this can be considered a single [LEDD] in a Fourier series.
% 	To assess all possible signals, however, an infinite amount of these experiments have to be considered.
% %%%%%%
% 	Because the experiment does not define the time scale, the aspect of different frequencies is irrelevant in this context.
% 	The size of $\kappa$ in relation to $\tau$ is defined and gives the inter--spike interval, but the amplitude of the sine function is not linked with the time scale of the simulation.
% 	%The amplitude of the forcing function oscillations is not directly linked to the time scale, and implies that the experiment done in this work is but an example of simulator efficiency.
% 	This implies that the efficiency experiment is but an example of simulator efficiency.
% 	%The domain of the forcing function is chosen so that errors are prominent while still being plausible.
% 	The forcing function is chosen so that it is a relevant example that is plausible for neural networks.
% 	%The forcing function is chosen so that the example is relevant and plausible for neural network, so that it is a relevant example.
% 	Because the forcing function of the efficiency comparison in chapter \ref{chExperimentalEfficiencyMeasurement} has the constraint that $\kappa$ is above threshold for the whole simulation, the experiment has been repeated with a forcing function without this constraint.
% 	%Because the forcing function of the efficiency comparison in chapter \ref{chExperimentalEfficiencyMeasurement} is above threshold for the whole simulation to make errors prominent, the experiment has been repeated with a forcing function without this constraint.
% 	%Because it is above the firing threshold for the whole simulation to make differences prominent, a simulation has also been conducted with a forcing funtion that goes below this value.
% 	For the sake of completeness, method and results of this experiment are presented in appendix \ref{appendixExperiment3}.
% % 		, and shows a similar effect.
% %	The results are presented in appendix \ref{appendixExperiment3} for the sake of completeness, and shows a similar effect.
% 	%The results from this experiment have not been included in the main text, but a plot of the results is presented in appendix \ref{appendixExperiment3}.
% 
% 	%Algebraic input functions are chosen to facilitate
% 	%Algebraic input functions are chosen for the sake of replication
% 	%Algebraic input functions enable a easier repetition of experiments, and also makes analysis of e.g. the simulated solution possible.
% 	A neuron's spiking input from other nodes in a neural network have a complex character, and resembles white noise in the time domain.
% 	%The chaotic input from a network of neurons can almost be seen as white noise in the time domain.
% 	%The chaotic input from a network of neurons can almost be seen as white noise.
% 	The resulting depolarization of the receiving $LIF$ neuron is the integral of this input, and can thus resemble a Wiener process.
% 	To test more realistic neural input flows, one should focus less on replication, and utilize a stochastic process to define neural input.
% 	%To test a more realistic neural input flow, one could step away from optimizing experiments for replication, and e.g. utilize a Wiener process to define neural input.
% %%%%%	
% %	An algebraic forcing function can be seen as only an example of all possible input functions found in white noise.
% %	All functions can be represented as a Fourier series of trigonometric functions[CITE].
% %	The author therefore thinks that the use of a sine forcing function makes the experiment more general, 
% %		and that this particular input can give general results. %answers.
% %	%As all functions can be represented as a Fourier series of trigonometric functions[CITE], 
% %	%	the author believes that the use of the sine function makes the forcing function more general.
% %	It is left for further work to assess forcing functions that gives a sub--threshold $\kappa$. %TODO Eller ta det inn i denne rapporten?
% %	%The use of an algebraic function defined as a sine function can thus be seen as only one 
% 	It is left for further research to assess forcing functions that are defined by e.g. a Wiener process or by synaptic input from an ANN.
% %	It is left for further work to assess forcing functions that also gives sub--threshold activation levels, 
% %		and to assess the two models when a node receives input from an ANN.
% 	To simplify further analysis, the source code of $auroSim$ have been published under GPL and the version presented in this report can be found under branch \emph{master} in the git repository found in \emph{https://github.com/leikanger/masterProject}\cite{gitRepoCommit}.
% 	%To simplify further analysis, the software developed in this work have been published under GPL,
% 	%	and the version presented in this report can be found with the commit id $5e1e609ef_{\ldots}$ at 
% 		%\cite{gitRepoCommit}.
% 	%	\emph{github.com/leikanger/masterProject}\cite{gitRepositorySida}\cite{gitRepoCommit}.
% 	%	\emph{github.com/leikanger/masterProject}\cite{gitRepositorySida}. %TODO TODO TODO Cite viser ikkje vev-sida. Fiks webcitation!
% 	
% 	
% 
% 
% 
% 
% %	\begin{itemize}
% %		\item Har ikkje implementert synaptic plasticity
% %		\item Kanskje skrive om effektivitetsanalysen: at KM er implementert for likt NIM, og vil difor 'suffer' av dette.
% %			KM vil difor bruke meir comp. resources enn nødvendig, noke som kan ha sett KM i dåligare lys.\\
% %			MEN det er alikevel valget å gjøre det slik, siden hovedfokuset i denne teksten er en teoretisk sammenligning(og utvikling av KM)
% %		\item Eg burde brukt meir bibliotek, istadenfor å implementere alt selv (i C++)
% %		\item Eg kunne sammenligna KM med etablert software for effektivitetssammenligning.
% %			\begin{itemize}
% %				\item[+] Dette ville gjort resultata mindre avhengig av min implementasjon av $NIM$.
% %				\item[-] Implementasjonene ville da blitt meir ulike med tanke på f.eks. effektiviteten av tids-simuleringa. Dette ville difor kunne bli feilaktig.
% %				\item[-] Den teoretiske sammenligningen ville ikkje blitt like insiktsfull: mange små detaljer ville forsvunnet.
% %			\end{itemize}
% 
% %		\item bare sett på enkelt-neuron(ikkje ANN)
% %			\begin{itemize}
% %				\item[+] Bedre for å reprodusere resultat!
% %				\item[-] Mulig det ikkje gir eit velbalansert svar. I kvit støy finner man alle mulige situasjoner mens
% %					algebraisk funk. vil være rimelig smalt i fohold.
% %				\item[-/+] Diskutere korleis en synaptic flow vil opptrå. Skrive at denne vil ha en kontinuerlig funk. Så kvit støy er umulig.
% %					Heller den integrerte av kvit støy -- wiener process.
% %%				\item[+] Mulig å finne algebraisk løysing
% %			\end{itemize}
% % TODO TODO TODO Skal eg også ta med neste? (har eg ikkje allerede skrevet om dette?) TODO TODO TODO
% %		\item Bruk av edge transmission as the derivative. 
% %			\begin{itemize}
% %				\item[-] Øker kompleksiteten til design uten å forbedre effektivitet
% %				\item[-] Fører til små feil som må handteres for Kappa,  uten å forbedre effektivitet
% %				\item[+] Tvang meg til å tenke gjennom desse aspektene, og lære at dette er bortkastet.
% %			\end{itemize}
% %	\end{itemize}
% 
% 
% \section{Concluding Remarks}
% 	%(Skriv into om K-formalismen først) TODO
% 
% 	In this work, a new formalism is developed to denote the activation level of a neuron.
% % NESTE SETN ER DÅRLIG: litt feilaktig. TODO TODO Skriv meir presist/ bedre/ rettere. (Det er ikkje at man benytter K-formalismen, men time windows.. TODO
% 	By utilizing the concept of time windows and synaptic flow, it is shown that algebraic equations can be used directly in spiking neuron simulators.
% 	%By utilizing the concept of time windows and synaptic flow, it is shown that algebraic equations can be used to make activation based spiking neuron simulators.
% 	%By utilizing the concept of time windows and synaptic flow, it is shown that a mechanistic model can be used for activation based spiking neuron simulators.
% %	By utilizing this formalism, it is shown that a mechanistic model can be used to design activation based neural simulations.
% %	%By utilizing the new $\kappa$ formalism to denote the activation level of the neuron, 
% %TODO Skriv neste stetninga slika at alle aspekt ved den er interesant og har innhold! TODO
% 	By computing the neuron's depolarization every time the activation level is altered, the neuron's spike time estimate can also be updated.
% 	%As the neuron's depolarization is updated every time the activation level is altered, this can be used as the initial value in the equations to estimate the neuron's spike time.
% 	When the neuron is estimated to fire in the course of the present time step, this estimate can be used as the simulated firing time as $\kappa$ is defined to be constant during a computational time step.
% %	When the the neuron is estimated to fire in the present time step, this estimate will not be altered, and the node can fire.
% 	%By updating the neuron's depolarization every time the activation level is altered, the neuron's spike time can be can not only be found on a reactive basis(firing after threshold crossing), but the spike can be scheduled at the estimated spike time.
% %XXX No gir den heller ikkje heilt meining.. "Ka vil han med dette?"
% 	%By updating the neuron's depolarization every time the activation level is altered, the neuron's spike time can be fond on a proactive basis, not only by firing after the depolarization variable's threshold crossing(reactive basis).
% 	This makes it possible to have spike times with an arbitrary precision, and what is called intra--iteration time accuracy is the result.
% %	This makes it possible for the neuron to spike at a time instance with an arbitrary resolution. %a floating point variable's resolution.
% 	Theoretical analysis conclude that this gives more accurate simulation results.
% 	%It is theoretzised that this gives more accurate simulation results.
% %	For all conducted experiments, it is shown that this gives more accurate simulation results.
% 
% 	Theoretical and experimental analysis indicate that the error varies with the derivative of the neuron's activation level in $\kappa M$. %,
% 	%	and the absolute simulation error is bounded since synaptic inflow is bounded.
% 	This results in a bounded error for $\kappa M$ simulations, as opposed to the error produced when simulating the neuron by numerical integration.
% 	%TODO Fortesett på dette: Veldig bra intro til å skrive at man trenger 10 ganger så mange 
% %%%%%%%%%%%%%%%%%%%%%%%%%%%
% 	If efficiency can be measured by the temporal resolution needed to accomplish some simulation accuracy requirement, this study shows that utilizing the $\kappa M$ results in a large increase in efficiency.
% %	If the size of the computational time step is used to measure efficiency, this study shows that a large increase in efficiency can be the result of utilizing the $\kappa M$ simulation scheme.
% 	In the course of one and a half period of a sinusoidal input, the $\kappa M$ simulation gives more accurate results than a $NIM$ 
% 		simulation with ten times the number of computational time steps.
% % 	In the course of one and a half period of a sinusoidal input, a $\kappa M$ simulation gives more accurate results than a simulation
% % 		that utilize numerical integration of input, with ten times the number of time steps.
% % 		%the currently used simulation model based on numerical integration of input.
% 	The comparative improvement is further increased if the experiment is simulated over $15$ periods of this input;
% 		The absolute error is generally less in the $\kappa M_{100}$ simulation than in the $NIM_{10.000}$ simulation. %, with a computational time step that is $1\%$ of $\kappa M_{100}$'s time steps.
% %		In the second half of this experiment, the absolute error is less in the $\kappa M_{100}$ simulation than in a $NIM_{10.000}$ simulation with a computational time step that is $1\%$ of $\kappa M_{100}$'s time steps.
% 	The $NIM_{10.000}$ simulation has a computational time step that is $1\%$ of the $\kappa M_{100}$'s, and the $\kappa M$ can be said to be ``as efficient as'' a $NIM$ simulation that has a number of time steps that is two orders of magnitude larger.
% 	This involves a simulator efficiency improvement of an increasing magnitude for longer simulations.
% 	%The $\kappa M$ simulation thus generates a smaller error in this experiment than a $NIM$ simulation that have a number of time steps that is two orders of magnitude larger.
% %%%%%%% TODO TODO DODO TODOD TODO TODO SKRIV SISTE TO SETN OM! TODO TODO TDOO TODO
% %	It is concluded that the $\kappa M$ error varies within a bounded domain, while the $NIM$ error is cumulative without an upper limit.
% %	%%					%%							%%									%and does not have an upper limit.
% %	%It is concluded that the comparative efficiency improvement of the $\kappa M$ is partially a result of the stability property of the $\kappa M$ error and the cumulative property of the $NIM$ error.
% %	% It is concluded that the comparative efficiency of the two models is further improved for longer simulations.
% %	The effect of the error properties of the two models are prominent already after 15 periods of a sinusoidal input,
% %		and all results implicate that these difference will diverge further for longer simulations.
% %	%The effect of the error properties of the two models are prominent even thought 15 periods of sinusoidal input can be considered a short simulation.
% %	%Fifteen periods of a sinusoidal input can be considered a short simulation, but the effect of the error properties of the two models are prominent. 
% %	%The effect will be larger for longer simulations, implying that the $\kappa M$ could be a break through when it comes to neural simulation.
% %	%The observed effect will be larger for longer simulations.
% %	%The comparative efficiency of the two models will thus be further improved in longer simulations.
% %	
% %
% %	%The $\kappa$ formalism ... %skrive om at det er mulig å bruke til anna også(?)
% %	%A new formalism for modelling a neuron's activation level is the result.
% %	%The $\kappa$ mathematics enables a more precise discussion about a neuron's activation level.
% %	%skriv f.eks. om kor forvirra dette er no, og kor teit det er å bruke gj.sn. fyringsfreq. som umiddelbart aktivitetsmål!
% %
% 		
% 	
% 
% 	The novel spiking ANN model propagate information like a second generation ANN, while still being capable of computing spikes.
% 	This is something that makes theory from frequency based ANN relevant.
% 	Second generation ANNs or other digital filters, can therefore be interfaced directly by letting its floating point output give $\kappa$ for the interface node.
% 	%This can also be done by a ``sensory node'', as in the experiments conducted in this work, and is thus valid for $NIM$ as well.
% 	By utilizing a ``sensory node'', similar effect can be achieved for input to a $NIM$ node, but only $\kappa M$ is able to produce a signal that can be utilized by a second generation ANN without signal processing.
% %	
% %	This is valid for both $NIM$ and $\kappa M$, but only $\kappa M$ is able of producing a floating point output signal without signal processing and/or estimation.
% 	Elements from second generation ANNs can also be utilized direcly in a $\kappa M$ spiking ANN;
% 		$\kappa$ can be used to compute the neuron's ``immediate frequency'' as well as the present and future depolarization values. %, and $\kappa M$ can thus be used for simulating second generation ANNs as well as spiking ANNs.
% 	%E.g. learning rules can be applied directly, as $\kappa$ can be used to compute the neuron's ``immediate frequency'' as well as the present and future depolarization values.
% 	With a few constraints, $\kappa M$ can therefore be used for either a second generation ANN or a spiking ANN.
% 	This makes $\kappa ANN$ very useful for examining theoretical neuroscience, as a full $\kappa M$ simulation can find info om begge..
% 
% %	%Begrunn meir: skriv at 2.gen er godt utvikler, mens SANN er heilt nytt.
% 
% %TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO  MEIR FUTT I SLUTT! TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
% 
% 
% 
% 
% 
% 
% 
% 
% % Negative ting med arbeidet mitt:
% % 	- Begge simulatorene er designet som NIM-simulatoren, der axonet simulerer spatiotemporal effekter. Dette er dårlig, og eg gjekk vekk fra dette designet. Det henger likevel igjen fra tidlig i prosjektet, 
% % 		og bør designes på nytt i videre arbeid.
% % 	- Synaptisk transmission i KM er implementert som den deriverte. Dette var for å effektivisere oppdateringen av postsynaptisk neuron, da bare de som var oppdatert trengte å resummeres. 
% % 		(Selv om summering er en lett operasjon kan neuronet ha veldig mange input-synapser).
% % 		Mengden med inputsynapser fører selfølgelig til at de aller fleste neuron (så mange at man kan kalle det "alle") får endret K kvar iter.
% % 		Det ville difor vært bedre å bruke en enklere direkte implementasjon, da dette er mindre "error prone" og er lettere å vedlikeholde. Dette er eit viktig aspekt i videreføringen av dette arbeidet!
% % 	- KM har meir konstant workload, men er dette egentlig bra? Diskuter om resultatet alltid er maks(meir enn det burde være).
% % 		Bra diskurs-materiale! (fordi eg trur at det ender med en følelse om at det er bra, spess for real-time applications)
% % 	- Skriv at når man 'for the case of reproducibility' går vekk fra å bruke eit kaotisk ANN, over til å bruke en enkelt node kan dette tviste effektivitetsanalysen. Dette er lite truleg, pga formen på signalet.
% % 		Hovedfokus i dette prosjektet var å sammenligne accuracy. Dette blir ikkje endra om det kommer fra $\xi(t)$ eller fra synaptisk input. Den analytiske input funksjonen er også designa til å være slik at verken verdien eller den deriverte av en vilkårlig grad er konstant. Bra.
% % 		Diskuter frem og tilbake.. slutt med å diskuter for denne approach.
% 
% % Det meste som var felles (i i\_auron, i\_...) var skriving til logfil osv. (STEMMER DETTE?) Kan isåfall diskutere at det aller meste er heilt ulikt for KM!
% 
% % Skrive om at eg ser i etterkant at eg ikkje burde implementert KM noden som NIM noden. KM noden trenger ikkje simulere intracellular delay, men kan bruke scheduler. (Dette kan for så vidt NIM også)
% 
% % Siden dette også var en sammenligning av design av de to SANN simulator modellene, har to implementasjoner blitt skrevet fra grunnen og sammenlignet. Det hadde kanskje vore bedre å sammenlignet KM med SANN implementert av andre når effektivitetssammenligne, men dette ville tatt bort en del fra første aspektet ved denne oppgaven(teoretisk sammenligning av modellene). BLA BLA. Men kunne være interresant. Men sammenligningen ville vært mellom KM-sample--and--hold og NIM med meir avanserte integrasjonsmetoder.
% 
% 
% % VIDARE ARBEID:
% % 	- Undersøke om det er mulig å gjøre det samme for andre neuron modeller. Kanskje KM er meir egnet til f.eks. exponential neuron model?
% % 	- Transduction mellom generasjoner av ANN(og også andre filter)
% % 	- Har bare sett på det enkle eksempelet med sensor-neuron. Dette er bra for reproducibility, men kan kanskje gjøre noko anna i dette forferdelig komplekse systemet. VIDERE FORSKNING kan difor være å undersøke om dette også stemmer for synaptisk input(ANN).
% % 	- Eg går bare ut ifra at begge modellene har nytte av å bruke meir avanserte numeriske metoder. Kor stor denne nytten er bør undersøkes. Dette har eg satt som utenfor the scope of this project. Dette er viktig element i for further recearch!
% 
%//} 
 
 
% // vim:fdm=marker:fmr=//{,//}
