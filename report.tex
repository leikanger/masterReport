
% Tester stavekontroll:ord: 	que queue deklarations declarations continue colour color successful important forcing  address



% Trenger "Table of abbreviations"
% 	- LTP, LTD, STDP
% 	- "spike" ? (at det betyr Action potential)?
% 	- SANN  - spiking ANN
% 	- SN 	- Spiking Node, a node in SANN.
% 	- KANN, KN.
% 	- LIF neuron: 	Leaky--Integrate and Fire  neuron




% Eller kanskje eg treng stikkordsregister: Trenger:
% 	- Det over og:
% 	- axo-axonic synapses
%
% 	- KN, KANN node : 	node based on a the consept of the $\kappa$ model of the neuron. Nodes of KANN
% 	- SN, SANN node : 	node based on a direct simulation of a spikin neuoron. Nodes of SANN
% 	- suptrathreshold levels : 	value higher than the firing threshold of a node.
% 	- STDP
% 	- LIF neuron
% 	- synaptic weight.
% 	- AuroSim 		:  	The implementation written in this project.
%
%


\documentclass[b5paper,12 pt]{report}


\usepackage[utf8]{inputenc}
\usepackage{graphicx} 

\usepackage[font=footnotesize,format=plain,labelfont=bf,up,textfont=it,up]{caption}


\usepackage{amsmath}
\usepackage{mathrsfs} %brukt for krølle-L : laplace

\usepackage{subfig}   % for subfigures.
\usepackage{listings} %for c++ kode
\lstset{language=c++}


\usepackage{amsthm}
\newtheorem{mydef}{Definition}

%For å la \cite{a,b,c} gi f.eks. [12-14] i output..
\usepackage[sort&compress]{natbib}




%%%%%%%% Fra Kristoffer sin master:
\lstset{ %
basicstyle=\tiny,       % the size of the fonts that are used for the code
numbers=left,                   % where to put the line-numbers
numberstyle=\tiny,      % the size of the fonts that are used for the line-numbers
stepnumber=1,                   % the step between two line-numbers. If it's 1 each line will be numbered
numbersep=7pt,                  % how far the line-numbers are from the code
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
%captionpos=b,                   % sets the caption-position to bottom
breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
%escapeinside={\%*}{*)},          % if you want to add a comment within your code
%
%frame=single,                % adds a frame around the code
tabsize=4,                % sets default tabsize to 2 spaces
breaklines=true,                % sets automatic line breaking
}


\author{Per R. Leikanger}
%\title{Development and Assessment of a Novel Model for Artificial Neural Networks}
\title{Development and Assessment of a Novel Model for Neural Simulation}
\date{\today}     


\begin{document}   



% TODO Neste linje skal kanskje være over abstract og maketitle? TODO

\pagenumbering{roman} %get rid of header/footer for toc page

\maketitle

\begin{abstract}
When simulating a spiking neuron, numerical integration of synaptic input is often utilized to compute the neuron's depolarization.
This report shows that the Numerical Integration Model($NIM$) for spiking neuron simulations have a cumulative error that diverges unless the expectancy value for the local truncation error is zero.
% An alternative neuron simulation scheme, $\kappa M$, has been developed and is presented in this text. %was developed and is presented in this text.
An alternative neuron simulation scheme, $\kappa M$, was developed and is presented in this text.
Experimental and theoretical results shows that the $\kappa M$ error varies within a bounded domain.

Experiments have been conducted on sample--and--hold implementations of the two models.
% Experiments were done on sample--and--hold implementations of the two models.
% Experiments done with a sample--and--hold implementation of the two models show that $\kappa M$ is significantly more effective than a $NIM$ simulation.
A $\kappa M_{100}$ simulation, a $\kappa M$ simulation with $100$ iterations per forcing function period, was compared with $NIM$ simulations with finer temporal resolutions.
It is shown that before $15$ periods of a sinusoidal depolarizing input current has been simulated, the $\kappa M_{100}$ simulation produced a smaller error than a $NIM_{10.000}$ simulation.
%All results indicate that this effect becomes larger after longer simulations, and is blamed on the cumulative error of $NIM$ simulations.
Since the $NIM$ simulation has a number of time steps that is two orders of magnitude larger than the $\kappa M$ simulation, this represents a significant efficiency improvement.
% This represents a significant efficiency improvement, as the $NIM$ simulation has a number of time steps that is two orders of magnitude larger than the $\kappa M$ simulation.


\end{abstract}






\tableofcontents 
\cleardoublepage %start new page %TODO Brukes dersom [report] brukes for dokumentet.

\listoffigures
%\listoftables

\cleardoublepage

\pagenumbering{arabic}
\setcounter{page}{1} %reset the page counter
%\pagestyle{plain} % put headers/footers back on






\chapter{Introduction}
\input{introduction}

\chapter{Background Theory}
\label{chBackgroundTheory}

	The biological brain can be thought of as the computational system of an animal.
	It receives information from sensors located at various locations in the body and sends output to its various manipulators.
	This includes e.g. muscles and the being's endocrine system.

	A biological computational system is fundamentally different from digital technology.
	Instead of having a few, computationally powerful processing units, the biological brain has a huge amount of weak processing units, called neurons.
	The neuron processes information by doing a leaky integration of input, and sending output when the value goes beyond some threshold\cite{TrevesNeuralNetworks}.
	Large networks of such cells, with dynamic connections between them, comprise the biological brain and is seen as the basis of memory, thought and intelligence.
	

	Biological neural systems can in some respects outperform the digital computer.
	Tasks that involve associative computations or learning are performed much better by a neural network than by algorithms. %in the digital computer.
	An example of this is the pattern recognition of a two week old baby that recognizes the mother's face, a task that only recently has been accomplished by digital computational systems. % by the computer.
	In the computer, this can be accomplished by an Artificial Neural Network, $ANN$.

	Before the mechanisms of neural simulators and $ANN$s can be discussed, the original system has to be introduced.
	This chapter is reserved for this purpose, and starts by introducing the most important aspects of neural signal processing mechanisms.
 	After the biological neuron has been introduced, a short review of the history of $ANN$s is presented.
	This section concludes with introducing Spiking Artificial Neural Networks, neural network simulators with nodes where the neuron's depolarization is considered. %is simulated.
% MORTEN MEINER NESTE SETNING ER OVERFLØDIG. XXX Ta vekk?
% 	It is recommended that the reader utilize this chapter as a reference work, when different neuron simulation models are presented and analysed. %, in the remainder of this text.


	\input{biologicalNeuralSystems}
	\input{artificialNeuralSystms}



%TODO Mindre fokus på at det er en Neuron Simulation Model! Meir på at det er en matematisk formalisme!
\chapter{Neural Modelling}
%\chapter{Development of A Novel Neuron Simulation Model}
	\label{chDevelopmentOfANovelModel}

	Numerical integration involves an accumulation of error, since the error is integrated alongside the considered variable.
	A simulator based on numerical integration therefore involves an accumulation of local truncation errors, the error from each computational time step.
	In an attempt to avoid a diverging error, a neural simulator based on algebraic equations is developed and presented in this chapter.
%%
% 	Numerical integration involves an accumulation of error, since the error is integrated alongside the considered value.
% 	Thus, a simulator based on numerical integration of input involves an accumulation of local truncation errors, the error from each computational time step.
% 	When the artificial neuron fires an action potential, the depolarization is reset, and the neuron starts the next inter--spike interval.
% 	When there is an error in the node's value, the firing can happen at the wrong time, making the next inter--spike interval start at a correspondingly erroneous time.
% 	This means that the error is cumulative, and that a systematic error gives a diverging error for the neuron's depolarization.
% 	In an attempt to create a simulation with a bounded error, a simulation scheme based on the algebraic solution to the $LIF$ neuron's differential equations is presented in this chapter.

	To utilize continuous equations in a neural simulator, it is found in the preliminary project that depolarizing input has to be represented as a continuous flow \cite{FDP_report}.
%  	To utilize the algebraic equations in a neural simulator, it is found in the preliminary project that depolarizing input has to be represented as a continuous flow \cite{FDP_report}.
	After the algebraic solution to the $LIF$ neuron's depolarization has been presented in sec. \ref{ssecTheAlgebraicSolution} and \ref{ssecTheActionPotential},
		the concept of synaptic transmission as a continuous flow is discussed in sec. \ref{ssecSynapticFlow}.

	\include{theNovelModel}




	\chapter{Design/Implementation and Theoretical Comparison} % of the two Models}
	\label{chDesignAndTheroeticalComparison}
	%\chapter{Design of Software to Compare the Models}

		To assess whether $\kappa M$ can be used to simulate a spiking neuron, and to compare the resulting design/implementation with one that utilize numerical integration,
			both models were designed and implemented by the author. 
		The Numerical Integration Model($NIM$) and $\kappa M$ differ in how they compute the neuron's depolarization, how information is propagated, and how spike times are computed.
		The design of the software intended for a theoretical comparison of the two models is presented in this chapter.
 		This software, referred to as $auroSim$, is later used in experiments that consider the comparative efficiency of the two simulation models.

		\include{designOfTheImplementation}
		\input{analysisOfTheTwoModels}



	
	\chapter{Efficiency; Experimental Comparison} %Measurements}
	\label{chExperimentalEfficiencyMeasurement}
		The primary design criteria for a simulator is to produce accurate simulation results.
		As introduced in section \ref{ssecAnalysisOfErrorsForTheTwoModels}, the simulation error of a neural simulator can be decreased by increasing the temporal resolution of the simulation.
		This also greatly increases the computational load of the simulation, as more computations have to be conducted for the same simulated time domain.
		A relative efficiency comparison can therefore be performed by comparing the accuracy of two simulations for a given temporal resolution, or the resolution needed to accomplish the same accuracy.

		Since the run time of the $\kappa M$ simulation presented in sec. \ref{ssecOnComputationalComlexity} is almost the double of that of the $NIM$ simulation, large requirements are lain upon $\kappa M$'s accuracy. %%%	% for it to be as efficient at the $NIM$ model.
%		Since the run time of the $\kappa M$ simulation in sec. \ref{ssecOnComputationalComlexity} is almost the double of that of the $NIM$ simulation, large requirements are lain upon the novel models accuracy. %%%	% for it to be as efficient at the $NIM$ model.
		If the hypothesized accuracy improvement is large enough, $\kappa M$ can still be as efficient, or even more efficient, than the $NIM$ simulation model.
		%If the simulation produce the hypothesized accuracy improvement, it might still be as efficient of even more efficient than the $NIM$ simulation model.
		%The hypothesized stability property of the $\kappa M$ error might also be important in this context, and could show important for the global error after long simulations.
		The purpose of this chapter is to assess the comparative efficiency of the two models, by considering the absolute simulation error for simulations done by $\kappa M$ and $NIM$. %of similar situations.
% 		The purpose of this chapter is to assess the comparative efficiency of the two models by considering the absolute simulation error of similar situations.




% The size of the truncation errors caused by the discretization of time can be minimized by letting the number of iterations be very large and the computational time step very small.
% This cause the discrete time to go toward continuous time, and the truncation errors to go toward zero. %and the error from simulating the system in discrete time to go toward zero.
% Because of this direct correlation between the size of the error and the computational load, it is possible to measure the efficiency of a simulator by the simulation error;
% 	For simulations with smaller error, larger computational time steps can be used to accomplish the same accuracy goal.
% In this work, the efficiency of the two models are analyzed by comparing the simulation error of a $\kappa M$ and a $NIM$ simulation of low temporal resolution with a high resolution $NIM$ simulation. % with over $1000$ times the number of time steps.
% %The results from this high--resolution simulation will be referred to as the simulated solution in the remainder of this text. %, and considered the true time course.
% 

		\include{experimentalEfficiancyComparison}




	\chapter{Discussion and Conclusion}
	\label{chDiscussion}

		\input{discussion}


\appendix
	%TODO TODO TODO Ask Amund whether it is OK to cite the NEVR reports! TODO TODO TODO
	%TODO TODO TODO TODO TA VEKK appendixSynapticPlasticity. REferer til NEVR-rapporten! Fjærn alle ref. til {appendixSynapticPlasticity} TODO TODO TODO TODO TODO TODO
	%\include{appendixSynapticPlasticity} TODO Fjærn alle ref. til {appendixSynapticPlasticity} TODO TODO TODO TODO TODO TODO
	\include{appendixMathematicalDerivations}
	\include{appendixImplementationDetails}
	\include{appendixUMLofAllNodeSubelementClasses}




\bibliography{bibliografi}
%\bibliographystyle{abbrvnat}
\bibliographystyle{plain}
\end{document}

% // vim:fdm=marker:fmr=//{,//}
