
\section{Spiking Neuron Simulation Based on Synaptic Flow}
	\label{secDevelopmentOfTheNovelANNmodel}
	A system that behaves like a leaky itegrator is a bucket with a set of small holes at the bottom.
	%An intuitive leaky integrator is a bucket with a set of small holes at the bottom.
	If the LIF neuron is visualized as a leaky bucket with input from a gutter, excitatory synaptic input can be represented by an agent pouring cups of water into that gutter.
	%If the LIF neuron is visualized as a leaky bucket with input from a gutter, synaptic transmissions is represented by pouring cups of water into this gutter.
	When the number of agents pouring water into the gutter becomes very large and the size of each transmission is small, this can again be visualized as rain.
	%The resulting water level in the leaky bucket can be simulated by either counting the number of raindrops or by estimating the corresponding flow in the input gutter and utilizing the algebraic solution to find the water level.

	The resulting water level in the leaky bucket can either be simulated by counting the number of raindrops(and computing the size of the leakage in every computional time step)
	%The resulting water level in the leaky bucket can be simulated by either counting the number of raindrops(and computing the leakage after each computational time step)
		or by estimating the corresponding flow through the gutter and utilizing the algebraic solution to find the water level.
%%%%%
	%If the simulation has a bounded temporal accuracy(discrete time), the author believes that a more accurate simulation result can be achieved when the algebraic solution is utilized to simulate the systems value. 
	For simulations with a bounded temporal accuracy(discrete time), more accurate simulations may be achieved by utilizing the algebraic solution to simulate the systems value.
	This is tested in chapter \ref{chExperimentalEfficiencyMeasurement}.
	%Experiments test this is set up in chapter \ref{chExperimentalEfficiencyMeasurement}.
	%For simulations with a bounded temporal accuracy(discrete time), it is found that a more accurate simulation result can be achieved when the algebraic solution is utilized to simulate the systems value.
	%TODO Dropp setninga over? NEI: første biten er jævla bra! 			Men det etter her er litt dårlig: avslører for mykje om kva eg finner ut?
%%                 %%                                                          %%                                                  %%                                              % input is represented as a flow.
	%This implies that fewer iterations are needed to accomplish some accuracy goal, and a more efficient simulator model is the result.
	In this section, the mathematics and necessary concepts for a flow simulation is developed and presented.




% 	The subthreshold integration of a LIF neuron can be visualized as a leaky bucket with input from a gutter.
% 	Excitatory synaptic input can further be represented by an agent pouring cups of water into that gutter.
% 	%The subthreshold integration of a LIF neuron can be thought of as a leaky bucket with small holes at the bottom.
% 	%If the LIF neuron is modelled as a leaky bucket with input from a gutter, excitatory synaptic input can be represented by pouring cups of water into that gutter. %this gutter.
% 	When the number of incoming synaptic connections are very large and the size of each transmission is small, this can again be visualized as rain.
% 	The resulting water level in the bucket can either be simulated by counting the number of rain drops and estimating the size of each, or by estimating the corresponding flow out of the gutter and utilizing the 
% 		algebraic solution to find the water level. %algebraic solution to the differential equations to find the water level.
% 	If the simulation has a bounded temporal resolution(discrete time), it is found that a more accurate simulation can be achieved by considering depolarizing flow instead of discrete synaptic transmissions.
% 	In this section, the mathematics and necessary concepts for flow simulation are developed and presented.

	\subsection{The Algebraic Solution to the LIF Neuron's Value}
	\label{ssecTheAlgebraicSolution}
		Subthreshold integration in the LIF neuron is defined by general leaky integrator's differential equations\cite{gerstnerKistler2002KAP04}.
		\begin{equation}
			\begin{split}
				\dot{v}(t)&= \dot{v}_{in}(t) - \dot{v}_{out}(t) \\
					&= I(t) - \alpha v(t)
			\end{split}
			%\nonumber
			\label{eqDifferentialEquation}
		\end{equation}
		The inflow is represented by $\dot{v}_{in}(t) = I(t)$, and $\dot{v}_{out}(t)$ represents the ``leakage'' of the neuron's depolarization value.
		The leakage is thus given as the neuron's present depolarization level scaled by the system's leakage constant $\alpha$.
		The algebraic solution to \ref{eqDifferentialEquation} is derived in appendix \ref{appendixAlgebraicSolution}.
		For time intervals where $\kappa$ and $\alpha$ are constant, it is found that the system's subthreshold depolarization is given by %can be found by TODO Skriv om! "is given by" er dårlig!
		\begin{equation}
			v(t_v) = \kappa - \left( \kappa - v_0 \right) e^{-at_v} 	\quad,\; \kappa = \frac{I}{\alpha} % \quad,\;t_v = t-t_0
			\label{eqValueEquation}
		\end{equation}

		The variable $v_0$ represents the initial value for the neuron's depolarization and $t_v$ is the time from the start of the considered time interval\mbox{($t_v = t - t_0$)}.
% Var sammenkobla med Recall that equation \ref{eqValueEquation} ...
%TODO Lag figur på nytt! Endre litt på teksten som står (t_p -- time from start of period    er dårlig. Bl.a.)
\begin{figure}[htb!p]
    \centering
    \includegraphics[width=0.65\textwidth]{demonstrasjonAvUlikeKappaforVerdifunksjonen}
 	  \caption[Illustration of how time windows can be utilized to simulated the neuron by the algebraic equation]{
	%		A leaky integrator can be simulated by utilizing the concept of time windows.
			The figure shows how the concept of time windows enables the use of \eqref{eqValueEquation} for simulating the neuron's depolarization.
			In the time interval $t_p = [0, 100]$, $\kappa_0 = 0.7$ is valid.
			At time $t_p = 100$, $\kappa$ is changed to $\kappa_1 = 0.5$, before it finally is set to $\kappa_2 = 1$ at time $t_p = 150$.
			}
\end{figure}
		Recall that equation \ref{eqValueEquation} only is valid for time intervals where $\kappa$ and $\alpha$ remain constant.
		To formalize such an interval for later discussions, the concept of time windows is introduced. % defined.
		\begin{mydef}
			A time window is a time interval where $\kappa$ and $\alpha$ are constants, within one inter--spike period.
			\label{defTimeWindow}
		\end{mydef}

		When the neuron's input flow is changed or the neuron fires an action potential, a new time window is initialized.
		The initial value $v_0$ can be found by computing the last value of the previous time window, and $t_0$ is acquired by saving the time of initiation for the new time window.



	\subsection{The Action Potential}
	\label{ssecTheActionPotential}
	As introduced in sec. \ref{secBiologicalNeuralSystems}, the neuron fires an action potential when the depolarization value crosses the firing threshold.
	%In continuous time, 
	The firing time for a neuron in continuous time can therefore be found by the equation $v(t_f) = \tau$, where $\tau$ is the firing threshold for the neuron.

	\begin{equation}
		\begin{split}
				v\left(t_w^{(f)}\right)			 							&= \tau \qquad 										\\	%,\qquad\qquad\tau = \text{firing threshold}
				\kappa - \left( \kappa - v_0 \right) e^{-at_w^{(f)}}  		&= \tau 											\\
		%		(v_0-\kappa)e^{-\alpha t^^{(f)}}							&= \tau-\kappa 										\\
				e^{-\alpha t_w^{(f)}} 			 						&= \frac{\kappa - \tau}{\kappa - v_0} 					\\
				t_w^{(f)}													&= -\alpha^{-1} \, \ln \left( \frac{\kappa - \tau}{\kappa - v_0} \right) 					
		\end{split}
		\label{eqDevelopmentOfFiringTimeEstimateEq}
	\end{equation}

	If an absolute refraction time $t_r$ is defined for the neuron where the depolarization remain constant after firing, this value is added to eq. \eqref{eqDevelopmentOfFiringTimeEstimateEq}.
	%If an absolute refraction time $t_r$ is defined for the neuron where the depolarization remain constant after firing, $t_r$ has to be added to eq. \eqref{eqDevelopmentOfFiringTimeEstimateEq}.
	An other way of viewing the resulting equation is as the remainder of current inter--spike interval, $p_r(\kappa, v_0)$.

	%It is shown in appendix \ref{appendixFiringTime} that the firing time, represented as the remainder of the current inter--spike period can be estimated by % is given by
\begin{equation}
	p_r(\kappa, v_0)  	= -\alpha^{-1} \, \ln \left( \frac{\kappa - \tau}{\kappa - v_0} \right) + t_r
	\label{eqEstimatedTimeToFiring}
\end{equation}

	As eq. \eqref{eqEstimatedTimeToFiring} is derived from \eqref{eqValueEquation}, the same constraints are valid;
		The estimate for the remainder of the current inter--spike interval is only valid until a new time window is initialized.
	%This means that when a new time window is initiated, the old firing time estimate becomes invalid.
%%
	If depolarizing inflow is defined to be constant during a computational time step, a firing time estimate in the current iteration can not change before the estimated time. % the neuron fires.
	%If depolarizing inflow is defined to be constant during a computational time step, a firing time estimate in the present time step can not change before that time. %the neuron fires.
	The estimated firing time can therefore be utilized as the simulation's firing time, and an action potential can be initiated with an intra--iteration time accuracy defined by the data format used in the computations. %, e.g. the \emph{double} data formate. %given by e.g. the \emph{float} data format.
	%The estimated firing time can therefore be utilized as the actual firing time, and an action potential can be initiated at that precise moment.
%%
	The set of possible spike times thus have a near--continuous temporal resolution, only limited by the accuracy of the format used. %e.g. the double precision floating point format.

% asdf@jeje12

% XXX Er det for langt hopp? Vil gjerne gå over til neste section: synaptic flow of activation level.
	An inter--spike interval is finalized by the neuron firing an action potential, after which the neuron's depolarization is reset to the membrane resting potential before the process starts anew.
	%After an action potential, the neuron's depolarization is reset to the membrane resting potential and the process starts anew.
	The current estimate of the total inter--spike interval can be computed by eq. \eqref{eqEstimatedTimeToFiring} from the neuron's reset potential $v_r$.
	%An immediate estimate of the total inter--spike interval can be found by computing eq. \eqref{eqEstimatedTimeToFiring} from the neuron's reset potential $v_r$.
	%The total inter--spike interval can therefore be estimated as the remainder of the inter--spike period from the neuron's reset potential $v_r$.
\begin{equation}
	p_{isi}(\kappa) = p_r(\kappa, v_r)% IKKJE: + t_r
	\label{eqEstimateOfInterSpikePeriod}
\end{equation}
	This equation will show important when we next consider synaptic flow of activation level.
	
	%This process can be modelled by 


    \subsection{Synaptic Flow}
	\label{ssecSynapticFlow}
%	Neural input that changes the neuron's depolarization can be separated into two sets, a subclass of synaptic input that changes the postsynaptic neuron's depolarization and other depolarizing input.
%	Synaptic depolarizing input can be mediated through ligand--gated channels, as introduced in section \ref{ssecTheBiologicalSynapse}.
%	%The synaptic part of depolarizing input can be mediated through ligand--gated channels, as introduced in section \ref{ssecTheBiologicalSynapse}.
%	This is what will be referred to as synaptic input in the remainder of this text.

%todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo 
%todo todo todo todo           Lag en figur som viser skematisk kva input eit neuron har(K_ij og xi_i)                   todo todo todo todo todo todo todo todo todo 
%todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo 

	Let all synaptic input be modelled as the flow $\kappa_{ij}$, where $j$ represents the presynaptic neuron and $i$ the receiving neuron.
	Other input that changes neuron $i$'s depolarization is represented by $\xi_i(t)$.
	The final value for the neuron's depolarization, $\kappa_i = \frac{I_i}{\alpha}$, is defined as the sum of all the neuron's input flows.
	%The final value for the neuron's depolarization $\kappa_i$ is defined by the sum of all input flows for neuron $i$.
	If $\mathscr{D}$ is the set of integers representing neuron $i$'s presynaptic neurons, the total inflow during the $n$'th iteration can be written as
	%The total inflow in the $n$'th iteration can therefore be written as

		\begin{equation}
% TODO HUGS: K = I/a : dermed må I være sum(k_ij + xi)*alpha
			% I_{i, t_n} = \sum_{j} \kappa_{ij, t_n} + \xi_{i, t_n}
			\begin{split}
			I_{i, t_n} 	&= \kappa_{i,t_n} \cdot \alpha \\
						&= \left( \sum_{j} \kappa_{ij, t_n} + \xi_i(t_n) \right) \alpha \quad,\; j\in\mathscr{D}
			\end{split}
			\label{eqSynapticIntegrationForKANN}
		\end{equation}

	The most important depolarizing input for neural signal processing is synaptic input\cite{PrinciplesOfNeuralScience4edKAP10}.
	%The most important depolarizing input when it comes to neural signal processing is synaptic input\cite{PrinciplesOfNeuralScience4edKAP10}.
	Synaptic input will therefore be the main focus in this section.
	%The main focus of this section is therefore synaptic transmissions.
	%The main focus of this section will therefore be synaptic transmissions.
	The funtion $\xi_i(t)$, representing other input, have different forms for different depolarizing sources and have to be modelled separately for each such source.
	%Other input $\xi_i(t)$ have different forms for different sources and have to be modelled separately for different such mechanisms.
	%The form of other input $\xi_i(t)$ varies for different sources of the signal and have to be modelled separately for each such mechanism. 
	%XXX BRA XXX: One example of another source for changing a neuron's depolarization is the instrumentation done by sensory neurons. %TODO TODO TODO Skriv om dette en plass, og referer dit!  

\begin{figure}[hbt!p]
	\centering
	\includegraphics[width=0.70\textwidth]{epsp_ipsp}
	\caption[Illustration of neural integration of synaptic input]{
			A simulation of neural integration of synaptic input. 
			Excitatory Postsynaptic Potentials(EPSP) increase the membrane potential of the postsynaptic neuron and thus excite the neuron toward firing.
			Inhibitory Postsynaptic Potentials(IPSP) hyperpolarizes the postsynaptic neuron, and inhibits the postsynaptic neuron with respect to firing.
			When the membrane potential at the axon hillock crosses the firing threshold, set to $-10mV$, an action potential is fired.
			%Figuren kommer fra http://techlab.bu.edu/resources/software_view/epsp_ipsp/
			%The simulation result presented in the figure is produced with the educational ``\emph{EPSP IPSP}'' software intended to illustrate EPSP and IPSP after synaptic transmissions.
			(The figure is found on the website of the educational ``\emph{EPSP IPSP}'' software intended for illustration of EPSP and IPSP after synaptic transmissions).
			% TODO Gjør forrige setninga mindre, og FÅ MED AT DET IKKJE ER EG SOM HAR LAGA DEN!
				}
	\label{figIllustrationOfEPSPandIPSP}
\end{figure}


	Let the synaptic weight $\omega_{ij}$ be defined as the postsynaptic change in depolarization after one synaptic transmission. 	
	%Let the synaptic weight $\omega_{ij}$ be defined as the postsynaptic change in depolarization after one transmission in the synapse.
	Synapse $j$'s contribution to the total change in depolarization after a time interval $\Delta t$ can therefore be written as the number of transmissions in that interval scaled by the synaptic weight $\omega_{ij}$.
	%In discrete time simulations, this can be written as
	\begin{equation}
% TODO Skriv det som N
%		\Delta v_i(\Delta t) = f_j(t_{n-1})\Delta t \cdot\omega_{ij} = \frac{\omega_{ij}}{p_{isi}(t_{n-1}}
		%\Delta v_{i, t_n}(\Delta t) = N_{j,t_n}\cdot\omega_{ij, t_n} %								%= f_j(t_{n-1})\Delta t \cdot\omega_{ij} % = \frac{\omega_{ij}}{p_{isi}(t_{n-1}}
		\Delta v_{i}(\Delta t_n) = N_{j,\Delta t}\cdot\omega_{ij, t_{n-1}} \qquad,\; j\in\mathscr{D}%								%= f_j(t_{n-1})\Delta t \cdot\omega_{ij} % = \frac{\omega_{ij}}{p_{isi}(t_{n-1}}
	\end{equation}
	where $N_{j,t_n}$ represents the number of transmissions in the synapse from neuron $j$ to neuron $i$ in the time interval $\Delta t_n$, 
	and $\omega_{ij,t_{n-1}}$ the synaptic weight updated at time $t_{n-1}$.
	%where the variable $N_{j,t_n}$ represents the number of transmissions from neuron $j$ in time interval $\Delta t_n$, and $\omega_{ij, t_{n-1}}$ represents the synaptic weight updated at time $t_{n-1}$.
	%where the number of transmissions is found by the last computed firing frequency of the presynaptic neuron $f_j(t_{n-1})$ multiplied by the length of the time interval $\Delta t$.

	%In the flow simulation model($\kappa M$), a continuous variable representing the present estimate of the inter--spike interval can be sent instead of the integer number of transmissions, enabling a higher resolution for the propagated signal.
	In the flow simulation model($\kappa M$), a continuous variable representing the present estimate of the inter--spike interval can be sent instead of the integer number of transmissions. 
	This enables a higher resolution for the propagated signal and thus a more accurate simulation.
	%For a time interval where the presynaptic activation level $\kappa_j$ is constant(a time window for the presynaptic neuron), synaptic flow of activation level can be written as
	For a time interval where the presynaptic activation level $\kappa_j$ is constant, synaptic flow of activation level can be written as
	\begin{equation}
	%	\kappa_{ij} = \frac{ \omega_{ij} }{ p_{isi}(\kappa_{j})}\Delta t
		\kappa_{ij, t_n} = \frac{ \omega_{ij, t_n} }{ p_{isi}(\kappa_{j, t_n}) } \Delta t \qquad,\; j\in\mathscr{D}% TODO SKRIV kva \Delta t   er for noke! TODO TODO SKVIVE DET SOM FREKVENS, først? = f(t) \omega \cdot \Delta t
	\end{equation}

	For a simulation with constant computational time steps $\Delta t = C_t$, this constant can be incorporated into the equation for synaptic flow $\kappa_{ij}$.
	%If a simulation with constant computational time steps $\Delta t = C_t$ is considered, this constant can be incorporated into the equation for synaptic flow $\kappa_{ij}$.
	%
	%If we let the simulation be carried out with constant time steps $\Delta t = C_t$, this constant can be incorporated into the equation for synaptic flow $\kappa_{ij}$.
	% ELLER:
	%Let the simulation be carried out with constant time steps $\Delta t = C_t$.
	%This constant can then be incorporated into the equation for synaptic flow $\kappa_{ij}$.
	We arrive at the equation for synaptic flow of activation level for constant time steps:
	\begin{equation}
		\kappa_{ij} = \frac{ \omega_{ij} }{ p_{isi}(\kappa_{j})} \qquad,\;j\in\mathscr{D}
		\label{eqSynapticTransmissionForKANN}
	\end{equation}
	
	When synaptic plasticity is introduced, it is important to remember that synaptic weight is scaled by the constant $C_t$.
	For consistency, it is important to scale synaptic plasticity by the same factor.

%[Her stod tidligare en analyse av feilen for de to ANN modellene]. Dette er flyttet inn i analysisOfTheTwoModels.tex



	\section{New Aspects to be Considered for the Novel Model}
		The use of the theory presented in this chapter introduce new aspects that have to be considered as well as opportunities for the simulator. % implementation.
		%The use of the theory presented in this chapter introduce a some new considerations and opportunities for the simulator. % implementation.
		%The use of the theory presented in this chapter introduce a some new considerations and opportunities for the implementation.
		Because the activation level $\kappa$ is updated many times before the neuron fires, time windows have to be utilized to be able to simulate utilizing the $\kappa M$. %a spiking neuron by $\kappa M$.
		From equation \ref{eqEstimatedTimeToFiring} and \ref{eqEstimateOfInterSpikePeriod}, the next firing and the inter--spike period can be estimated with a floating point accuracy.
		This enables a synaptic signal propagation of a number with a higher resolution, and the execution of an action potential at the computed firing time instant.
		
		When equation \ref{eqEstimatedTimeToFiring} have given an estimate that is in the present computational time step, an action potential is simulated.
		%When the estimated firing time is in the present time iteration, an action potential is simulated.
		The simulated firing is not involved in signal propagation as in the $NIM$ model, but is an additional capability for the $\kappa M$ simulation model.
		%The main reason for simulating the action potential in the $\kappa M$ is to compute mechanisms like STDP, as presented in appendix \ref{appendixSynapticPlasticity}.
		The neuron fires when the estimated task time is in the present computational time step.
		To be able to efficiently make use of this proactive firing time simulation scheme, a task scheduler have to be devised specifically for this purpose.
		%This proactive firing scheme in $\kappa M$ requires a task scheduler to be able to efficiently simulate the neuron.

		%TODO Kanskje ha "synaptic transmission as the derivative", her? Da kan eg også ha "recalculation of kappa", her..


%TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
%TODO TODO TODO TODO TODO Skriv noke nytt, her. Skal flytte "Task Scheduling" til "General Design of Simulator"::"Time" Det er fortidlig å ha det her.
%TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
		
% 		\subsection{Task Scheduling}
% 			
% 			Two alternatives for scheduling tasks have been tested for the simulator.
% 			The first is based on a continuously updated linked list of linked lists with tasks. %that can be considered a variable array.
% 			When a task is scheduled for execution e.g. in the iteration after the next, the object's pointer is inserted into the second inner list of the outer linked list.
% 			Before every time step, the first element of the outer list is popped and all the tasks of the inner list is inserted into \emph{pWorkTaskQueue}.
% 			This gives a list of lists that gives the relative time of scheduled tasks, where each list contains jobs scheduled for future time iterations.
% 			
% 			An alternative approach is to implement time scheduling by letting the \emph{time\_interface} abstract class have a variable \emph{double dEstimatedTaskTime}.
% 			This element is updated every time the neuron's firing time estimate is updated and checked by \emph{time\_class::doTask()} when time is iterated:
% 				If an element is scheduled for execution during the next computational time step, the pointer to that element is inserted into \emph{pWorkTaskQueue}.
% 			As introduced in section \ref{ssecTime}, this causes the task to be executed during the correct computational time step, 
%  			%This causes the task to be executed during the correct computational time step, 
% 				and the double precision floating point variable \emph{dEstimatedTaskTime} enables an intra--iteration time accuracy for tasks if \emph{pWorkTaskQueue} is
% 				 sorted by this variable.
% 
% 			The two methods was tested by comparing the total run time for a similar experiment set up.
% 			Because the second alternative is simpler to implement and thus simpler to maintain,
% 				and it was found to have about the same grade of efficiency(almost $5\%$ faster for the conducted experiment),
% 				%and have about the same grade of efficiency(about $5\%$ faster for the conducted experiment), 
% 				this approach is used for time scheduling in the implementation.
% 				%the alternative with the \emph{time\_interface::dEstimatedTaskTime} is used for time scheduling in this implementation.
% 			%The second alternative was somewhat more efficient($<5\%$ faster run time) in addition to being simpler to implement and maintain.
% 			%This alternative was therefore chosen.
% 			
% 			\subsubsection{Task Scheduling for Other Tasks}
% 				%The task scheduler utilize a variable from \emph{
% 				As the task scheduler use a member variable from \emph{class time\_interface}, task scheduling can be used for all classes that is part of the simulation.
% 				An important example of this is the \emph{synapse}: % The synaptic transmission for all output synapses of a node can therefore 
% 					When the neuron fires, the auron object of the node can write to all the node's output synapses' \emph{dEstimatedTaskTime} variable.
% 				The time can be written to the present time plus the predefined axonic delay before that synapse's transmission.
% 				In this way, a more efficient axon delay can be simulated with floating point accuracy.
%TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 





	
% // vim:fdm=marker:fmr=//{,//}
