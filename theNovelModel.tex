
\section{Spiking Neuron Simulation Based on Synaptic Flow}
	The subthreshold integration of a LIF neuron can be thought of as a leaky bucket with small holes at the bottom.
	If the LIF neuron is modelled as a leaky bucket with input from a gutter, excitatory synaptic input can be represented by pouring cups of water into that gutter. %this gutter.
	When the number of incoming synaptic connections are very large and the size of each transmission is small, this can again be visualized as rain.
	The resulting water level in the bucket can either be simulated by counting the number of rain drops and estimating the size of each, or by estimating the corresponding flow out of the gutter and utilizing the 
		algebraic solution to find the water level. %algebraic solution to the differential equations to find the water level.
	If the simulation has a bounded temporal resolution(discrete time), it is found that a more accurate simulation can be achieved by considering depolarizing flow instead of discrete synaptic transmissions.
	In this section, the mathematics and necessary concepts for flow simulation are developed and presented.

	\subsection{The Algebraic Solution to the LIF Neuron's Value}
	\label{ssecTheAlgebraicSolution}
		Subthreshold integration in the LIF neuron is defined by general leaky integrator's differential equations\cite{gerstnerKistler2002KAP04}.
		\begin{equation}
			\begin{split}
				\dot{v}(t)&= \dot{v}_{in}(t) - \dot{v}_{out}(t) \\
					&= I(t) - \alpha v(t)
			\end{split}
			%\nonumber
			\label{eqDifferentialEquation}
		\end{equation}
		The inflow is represented by $\dot{v}_{in}(t) = I(t)$, and $\dot{v}_{out}(t)$ represents the ``leakage'' of the neuron's depolarization value.
		The leakage is thus given as the neuron's present depolarization level scaled by the system's leakage constant $\alpha$.
		The algebraic solution to \ref{eqDifferentialEquation} is derived in appendix \ref{appendixAlgebraicSolution}.
		For time intervals where $\kappa$ and $\alpha$ are constant, it is found that the system's subthreshold depolarization is given by %can be found by TODO Skriv om! "is given by" er dårlig!
		\begin{equation}
			v(t_v) = \kappa - \left( \kappa - v_0 \right) e^{-at_v} 	\quad,\; \kappa = \frac{I}{\alpha} % \quad,\;t_v = t-t_0
			\label{eqValueEquation}
		\end{equation}

	
		The variable $v_0$ represents the initial value for the neuron's depolarization and $t_v$ is the time from the start of the considered time interval\mbox{($t_v = t - t_0$)}.
		Recall that equation \ref{eqValueEquation} only is valid for time intervals where $\kappa$ and $\alpha$ remain constant.
		To formalize such an interval for later discussions, the concept of a time window is introduced. % defined.
		\begin{mydef}
			A time window is a time interval where $\kappa$ and $\alpha$ are constants, within one inter--spike period.
			\label{defTimeWindow}
		\end{mydef}
		When the neuron's input flow is changed or the neuron fires an action potential, a new time window is initialized.
		The initial value $v_0$ can be found by computing the last value of the previous time window, and $t_0$ is acquired by saving the time of initiation for the new time window.


%TODO Lag figur på nytt! Endre litt på teksten som står (t_p -- time from start of period    er dårlig. Bl.a.)
%TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
\begin{figure}[htb!p]
    \centering
    \includegraphics[width=0.65\textwidth]{demonstrasjonAvUlikeKappaforVerdifunksjonen}
 	  \caption{
	%		A leaky integrator can be simulated by utilizing the concept of time windows.
			The plot shows how the concept of time windows enables the use of \eqref{eqValueEquation} for simulating the neuron's depolarization.
			In the time interval $t_p = [0, 100]$, $\kappa_0 = 0.7$ is valid.
			At time $t_p = 100$, $\kappa$ is changed to $\kappa_1 = 0.5$, before if finally is set to $\kappa_2 = 1$ at time $t_p = 150$.
			}
\end{figure}

	\subsection{The Action Potential}
	\label{ssecTheActionPotential}
	As introduced in sec. \ref{secBiologicalNeuralSystems}, the neuron fires an action potential when the depolarization value crosses the firing threshold.
	%In continuous time, 
	The firing time for a neuron can be found by the equation $v(t_f) = \tau$, where $\tau$ is the firing threshold for the neuron.
	It is shown in appendix \ref{appendixFiringTime} that the firing time, represented as the remainder of the current inter--spike period is given by
\begin{equation}
	p_r(\kappa, v_0)  	= -\alpha^{-1} \, \ln \left( \frac{\kappa - \tau}{\kappa - v_0} \right) + t_r
	\label{eqEstimatedTimeToFiring}
\end{equation}

% Dersom den under skal være med, er det uten mellomrom etter likninga.
%	where $p_r(\kappa, v_0) = t_f$ represents the remainder of the present inter--spike period.
	As the equation for the remainder of the inter--spike period is derived from \eqref{eqValueEquation}, the estimate is only valid for as long as $\kappa$ and $\alpha$ remains constant.
	%The equation for the remainder of the inter--spike period is derived from \ref{eqValueEquation}, and is valid only for as long as $\kappa$ and $\alpha$ remains constant.
	This means that when a new time window is initiated, the old firing time estimate becomes invalid.
	%This implies that when initiating a new time window, a old firing time estimate becomes invalid.
	If the next spike is estimated to happen during the current time iteration, the depolarizing inflow can per definition not change prior to this time. 
	%% 								%% 							%% 			  , this estimate can per definition not change due to an altered depolarizing inflow.
	%% 								%% 						 	%% 			  , it is impossible that the neuron initiates a new time window in other ways than firing an action potential.
	The estimated firing time can therefore be seen as the actual firing time, and an action potential can be initiated at that precise moment.
	%The spike time can therefore have a near--continuous temporal resolution with the resolution of a double precision floating point format. % to denote the neuron's firing time.
	The spike time can therefore have a near--continuous temporal resolution by utilizing a double precision floating point format. 
	%Skriv litt om kor liten double er?
	%For a discussion about what this results in for the simulation error, it is referred to sec. \ref{ssecAnalysisOfErrorsForTheTwoModels}.
	If all tasks are executed according to spike times, a task planned slightly before an other can be initiated before that task despite being scheduled in the same time iteration.
	% TODO Skriv om slutten: "might" 													, and might have ..  "Might" er dårlig..
	This cause the simulation to have a near--continuous time resolution for spike times, and might have a large effect on e.g. Spike--Time Dependent Plasticity(mentioned in appendix \ref{appendixSynapticPlasticity}).
	%This might have a tremendous effect on Spike--Time Dependent Plasticity after a transmission, as mentioned in appendix \ref{appendixSynapticPlasticity}.

%TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
%TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO  Finn figur som viser AP. Skriv at dette er formen på det biologiske AP.
%TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 

	The most important effect of having a near--continuous temporal resolution in respect to the simulation error, is that the next inter--spike interval can be initiated at the correct time. %computed time instant.
	%An other effect of having a near--continuous temporal resolution for spike times is that the next inter--spike interval can be initiated at the correct time.
	After an action potential(and the defined refraction period), the neuron can start charging the membrane potential at the computed time instant. % correct time.
	%%
	With the reactive firing scheme used in simulations utilizing numerical integration, the firing have to be delayed to the next iteration to preserve causality in a neural network. %TODO Finn referanse! TODO
	%With a discretization of possible spike times, the neuron have to wait for the iteration after the threshold crossing to preserve causality in the neural network.
	This gives a small delay of up to one computational time step before the neuron can start depolarizing again.
	A precise initiation of the next inter--spike interval will thus remove one of the error mechanisms in spiking neuron simulations.
	%A precise initiation of the next inter--spike interval will remove an error mechanism that might give an important part of the total error in spiking neuron simulations that utilize numerical integration. %when simulating depolarization by numerical integration.
	For a more elaborate discussion of the error induced by discrete possible spike times, it is referred to sec. \ref{ssecAnalysisOfErrorsForTheTwoModels}.

	After an action potential, the neuron's depolarization is reset to the neuron's reset potential and the process starts anew.
	The total inter--spike interval can therefore be found as the remainder of the inter--spike period from the neuron's reset potential $v_r$.
\begin{equation}
	p_{isi}(\kappa) = p_r(\kappa, v_r)% IKKJE: + t_r
	\label{eqEstimateOfInterSpikePeriod}
\end{equation}
	This equation will show important when we next consider synaptic flow of activation level.
	
	%This process can be modelled by 


    \subsection{Synaptic Flow}
	\label{ssecSynapticFlow}
	Input that change the depolarization of the neuron comes in many forms. 
	A class of these is a subset of synaptic input that alters the postsynaptic neuron's depolarization.
	This class of input will be referred to as synaptic input in the remainder of this text.

	Let all synaptic input be modelled as the flow $\kappa_{ij}$, where $j$ represents the presynaptic neuron and $i$ the receiving neuron.
	Other input that changes neuron $i$'s depolarization is modelled by $\xi_i(t)$.
	The final value for the neuron's depolarization $\kappa_i$ is defined by the sum of all all the neuron's input flows.
	%The final value for the neuron's depolarization $\kappa_i$ is defined by the sum of all input flows for neuron $i$.
	The total inflow int the $n$'th iteration can therefore be written as

		\begin{equation}
% TODO HUGS: K = I/a : dermed må I være sum(k_ij + xi)*alpha
			% I_{i, t_n} = \sum_{j} \kappa_{ij, t_n} + \xi_{i, t_n}
			I_{i, t_n} = \kappa_{i,t_n} \cdot \alpha = \left( \sum_{j} \kappa_{ij, t_n} + \xi_i(t_n) \right) \cdot \alpha
			\label{eqSynapticIntegrationForKANN}
		\end{equation}

	The most important aspect for the neuron's signal processing capabilities comes as a consequence of synaptic transmission in networks of neurons, and will be the main focus in this section.
	The form of other depolarizing input $\xi_i(t)$ varies, and have to be modelled for each such mechanism. %separately. 
	One example of an other source for changing a neuron's depolarization is the instrumentation done by sensory neurons. %TODO TODO TODO Skriv om dette en plass, og referer dit! TODO TODO TODO TODO TODO TODO TODO  Internreferer! TODO
	%One such input is the instrumentation done by sensory neurons.

\begin{figure}[hbt!p]
	\centering
	\includegraphics[width=0.70\textwidth]{epsp_ipsp}
	\caption{A simulation of neural integration of synaptic input. 
			Excitatory Postsynaptic Potentials(EPSP) increase the membrane potential of the postsynaptic neuron and thus excite the neuron toward firing.
			Inhibitory Postsynaptic Potentials(IPSP) hyperpolarizes the postsynaptic neuron, and inhibits the postsynaptic neuron with respect to firing.
			When the membrane potential at the axon hillock crosses the firing threshold, set to $-10mV$, an action potential is fired.
			%Figuren kommer fra http://techlab.bu.edu/resources/software_view/epsp_ipsp/
			The simulation result presented in the figure is produced with the educational ``\emph{EPSP IPSP}'' software intended to illustrate EPSP and IPSP after synaptic transmissions.
			% TODO Gjør forrige setninga mindre, og FÅ MED AT DET IKKJE ER EG SOM HAR LAGA DEN!
				}
	\label{figFigurAvNeuronet}
\end{figure}


	Let the synaptic weight $\omega_{ij}$ be defined as the postsynaptic change in depolarization after one transmission in the synapse.
	Synapse $j$'s contribution to the total change in depolarization after a time interval $\Delta t$ can therefore be defined as the number of transmissions in that interval, scaled by the synaptic weight $\omega_{ij}$.
	In discrete time simulations, this can be written as
	\begin{equation}
% TODO Skriv det som N
%		\Delta v_i(\Delta t) = f_j(t_{n-1})\Delta t \cdot\omega_{ij} = \frac{\omega_{ij}}{p_{isi}(t_{n-1}}
		\Delta v_{i, t_n}(\Delta t) = N_{j,t_n}\cdot\omega_{ij, t_n} %								%= f_j(t_{n-1})\Delta t \cdot\omega_{ij} % = \frac{\omega_{ij}}{p_{isi}(t_{n-1}}
	\end{equation}
	where the variable $N_{j,t_n}$ represents the number of transmissions from neuron $j$ in time interval $t_n$.
	%where the number of transmissions is found by the last computed firing frequency of the presynaptic neuron $f_j(t_{n-1})$ multiplied by the length of the time interval $\Delta t$.

	In the flow simulation model($\kappa M$) presented in this text, a continuous variable representing the present estimate of the inter--spike interval can be propagated instead of the integer number of transmissions,
		enabling a higher resolution for the propagated signal.
	For a time interval where the presynaptic activation level $\kappa_j$ is constant(a time window for the presynaptic neuron), the synaptic flow of activation level can be written as
	\begin{equation}
	%	\kappa_{ij} = \frac{ \omega_{ij} }{ p_{isi}(\kappa_{j})}\Delta t
		\kappa_{ij, t_n} = \frac{ \omega_{ij, t_n} }{ p_{isi}(\kappa_{j, t_n}) } \Delta t % TODO SKRIV kva \Delta t   er for noke! TODO TODO SKVIVE DET SOM FREKVENS, først? = f(t) \omega \cdot \Delta t
	\end{equation}

	Let the simulation be carried out with constant time steps $\Delta t = C_t$.
	This constant can then be incorporated into the equation for synaptic flow $\kappa_{ij}$.
	We arrive at the equation for synaptic flow of activation level for constant time steps:
	\begin{equation}
		\kappa_{ij} = \frac{ \omega_{ij} }{ p_{isi}(\kappa_{j})}
		\label{eqSynapticTransmissionForKANN}
	\end{equation}
	
	If synaptic plasticity is introduced, it is important to remember that synaptic weight is scaled by the constant $C_t$.
	For consistency, it is important to scale synaptic plasticity by the same factor.



% // vim:fdm=marker:fmr=//{,//}
