


%\section{Synaptic Flow: New Formalism for Neural Acivity} %Activation Level}
\section{The $\kappa$ Formalism for Neural Activity}
%\section{Spiking Neuron Simulation Based on Synaptic Flow}
	\label{secDevelopmentOfTheNovelANNmodel}
	One system that behaves like a leaky integrator is a bucket with a set of small holes at the bottom.
	If the LIF neuron is visualized as a leaky bucket with input from a gutter, excitatory synaptic input can be represented by an agent pouring cups of water into that gutter.
	When the number of agents pouring water into the gutter becomes very large and the size of each transmission is small, this can again be visualized as rain.

	The resulting water level in the leaky bucket can either be simulated by counting the number of raindrops(and computing the size of the leakage in every computational time step)
		or by estimating the corresponding flow through the gutter and utilizing the algebraic solution to the system's differential equation to find the water level.
	For simulations with a bounded temporal resolution(discrete time), more accurate simulations can be achieved by utilizing an algebraic equation than by numerical integration.
	This is tested in chapter \ref{chExperimentalEfficiencyMeasurement}.
%TODO TODO Neste setning skurrer litt. TODO TODO Skriv om? TODO
	In this section, the mathematics and necessary concepts of a flow simulation is presented.
% 	In this section, the mathematics and necessary concepts for a flow simulation is developed and presented.





	\subsection{Algebraic Solution for the LIF Neuron's Depolarization}
	\label{ssecTheAlgebraicSolution}
		Subthreshold integration in the LIF neuron is defined by the general leaky integrator's differential equation\cite{gerstnerKistler2002}: %\cite{gerstnerKistler2002KAP04}.
		\begin{equation}
			\begin{split}
				\dot{v}(t)&= \dot{v}_{in}(t) - \dot{v}_{out}(t) \\
					&= I(t) - \alpha v(t)
			\end{split}
			%\nonumber
			\label{eqDifferentialEquation}
		\end{equation}
		The inflow is represented by $\dot{v}_{in}(t) = I(t)$, and ``leakage'' is represented by $\dot{v}_{out}(t) = \alpha v(t)$.
% 		The leakage is defined as the neuron's present depolarization level, scaled by the system's leakage constant $\alpha$.
		The algebraic solution to \ref{eqDifferentialEquation} is derived in appendix \ref{appendixAlgebraicSolution}.
 		For time intervals where $\kappa$ and $\alpha$ are constant, it is found that the system's subthreshold depolarization is defined by %given by %can be found by TODO Skriv om! "is given by" er d√•rlig!
		\begin{equation}
			v(t_v) = \kappa - \left( \kappa - v_0 \right) e^{-at_v} 	\quad,\; \kappa = \frac{I}{\alpha} % \quad,\;t_v = t-t_0
			\label{eqValueEquation}
		\end{equation}
%%%%%%
		The variable $v_0$ represents the neuron's initial depolarization value and $t_v$ represents the time from the start of the considered time interval\mbox{($t_v = t - t_0$)}.
% 		The variable $v_0$ represents the initial value for the neuron's depolarization and $t_v$ is the time from the start of the considered time interval\mbox{($t_v = t - t_0$)}.
\begin{figure}[htb!p]
    \centering
    \includegraphics[width=0.65\textwidth]{demonstrasjonAvUlikeKappaforVerdifunksjonen}
 	  \caption[Illustration of how time windows can be utilized to simulated the neuron by the algebraic equation]{
	%		A leaky integrator can be simulated by utilizing the concept of time windows.
			The figure shows how the concept of time windows enables the use of \eqref{eqValueEquation} for simulating the neuron's depolarization.
			In the time interval $t_p = [0, 100]$, $\kappa_0 = 0.7$ is valid.
			At time $t_p = 100$, $\kappa$ is changed to $\kappa_1 = 0.5$, before being set to $\kappa_2 = 1$ at time $t_p = 150$.
			\cite{FDP_report}
			}
\end{figure}
		Recall that equation  \ref{eqValueEquation} is only valid for time intervals where $\kappa$ and $\alpha$ remain constant.
% 		Recall that equation \ref{eqValueEquation} only is valid for time intervals where $\kappa$ and $\alpha$ remain constant.
		To formalize such an interval for later discussions, the concept of time windows is introduced. % defined.
		\begin{mydef}
			A time window is a time interval where $\kappa$ and $\alpha$ are constants, within one inter--spike period.
			\label{defTimeWindow}
		\end{mydef}

		When the neuron's input flow is changed or the neuron fires an action potential, a new time window is initialized.
		The initial value $v_0$ can be found by computing the last value of the previous time window, and $t_0$ is acquired by saving the time of initiation for the new time window. %\cite{FDP_report}.XXX?cite?



	\subsection{The Action Potential Discontinuity}
	\label{ssecTheActionPotential}
%TODO TODO TODO TODO TODO TODO TODO TODO   Legg inn plott av K som viser kappa og fyring: FDP::fig.3.4    TODO TODO TODO TODO TODO TODO TODO
	As introduced in sec. \ref{secBiologicalNeuralSystems}, the neuron fires an action potential when the depolarization value crosses the firing threshold.
	The firing time for a neuron can therefore be found by the equation $v(t_w^{(f)}) = \tau$, where $t_w^{(f)}$ is the firing time and $\tau$ is the firing threshold of the neuron.
%	The firing time for a neuron in continuous time can therefore be found by the equation $v(t_w^{(f)}) = \tau$, where $t_w^{(f)}$ is the firing time and $\tau$ is the firing threshold of the neuron.

	\begin{equation}
		\begin{split}
				v\left(t_w^{(f)}\right)			 							&= \tau \qquad 										\\	%,\qquad\qquad\tau = \text{firing threshold}
				\kappa - \left( \kappa - v_0 \right) e^{-at_w^{(f)}}  		&= \tau 											\\
		%		(v_0-\kappa)e^{-\alpha t^^{(f)}}							&= \tau-\kappa 										\\
				e^{-\alpha t_w^{(f)}} 			 						&= \frac{\kappa - \tau}{\kappa - v_0} 					\\
				t_w^{(f)}													&= -\alpha^{-1} \, \ln \left( \frac{\kappa - \tau}{\kappa - v_0} \right) 					
		\end{split}
		\label{eqDevelopmentOfFiringTimeEstimateEq}
	\end{equation}

	If an absolute refraction time $t_r$ is defined for the neuron, where the depolarization remains constant after firing, this value has to be part of the equation for the estimated firing time.
	Another way of viewing the resulting equation is as the remainder of current inter--spike interval, $p_r(\kappa, v_0)$.

\begin{equation}
	p_r(\kappa, v_0)  	= -\alpha^{-1} \, \ln \left( \frac{\kappa - \tau}{\kappa - v_0} \right) + t_r
	\label{eqEstimatedTimeToFiring}
\end{equation}

	Since eq. \eqref{eqEstimatedTimeToFiring} is derived from \eqref{eqValueEquation}, the same constraints are valid.
	The estimate for the remainder of the current inter--spike interval is only valid until a new time window is initialized.
%%
	If depolarizing inflow is defined to be constant during a computational time step, a firing time estimate during the current time step can not change before the estimated time. % the neuron fires.
	The estimated firing time can therefore be utilized as the artificial neuron's firing time. %, giving a set of possible spike times that has a near--continuous temporal resolution.
	If the double precision floating point format is utilized in the simulator, this gives a near--continuous temporal resolution for the neuron's firing times.


	An inter--spike interval is finalized by the neuron firing an action potential, after which the neuron's depolarization is reset to the membrane resting potential before the process starts anew.
	The immediate estimate of the total inter--spike interval can be computed by eq. \eqref{eqEstimatedTimeToFiring}, from the neuron's \underline{reset potential $v_r$}.
\begin{equation}
	p_{isi}(\kappa) = p_r(\kappa, v_r)% IKKJE: + t_r
	\label{eqEstimateOfInterSpikePeriod}
\end{equation}
 	This equation is important when we next consider synaptic flow of action level.
% 	This equation will show important when we next consider synaptic flow of activation level.
	


    \subsection{Synaptic Flow}
	\label{ssecSynapticFlow}

%todo todo todo todo           Lag en figur som viser skematisk kva input eit neuron har(K_ij og xi_i)                   todo todo todo todo todo todo todo todo todo 

	Let all synaptic input be modelled as the flow $\kappa_{ij}$, where $j$ represents the presynaptic neuron and $i$ the receiving neuron.
	Other input that changes neuron $i$'s depolarization is represented by $\xi_i(t)$.
	The final value for the neuron's depolarization, $\kappa_i = \frac{I_i}{\alpha}$, is defined by the sum of all the neuron's input flows.
	If $\mathscr{D}$ is the set of integers representing neuron $i$'s presynaptic neurons, the total inflow during the $n$'th iteration can be written as

		\begin{equation}
			\begin{split}
			I_{i, t_n} 	&= \kappa_{i,t_n} \cdot \alpha \\
						&= \left( \sum_{j} \kappa_{ij, t_n} + \xi_i(t_n) \right) \alpha \quad,\; j\in\mathscr{D}
			\end{split}
			\label{eqSynapticIntegrationForKANN}
		\end{equation}

	Synaptic input, $\kappa_{ij}$, is the most important element for neural signal processing\cite{PrinciplesOfNeuralScience4edKAP10}, and is the main focus of this section.
	The function $\xi_i(t)$, representing other input, can have different forms for different depolarizing sources.
	This element therefore has to be modelled separately for each such source.

\begin{figure}[hbt!p]
	\centering
	\includegraphics[width=0.70\textwidth]{epsp_ipsp}
	\caption[Illustration of neural integration of synaptic input]{
			A simulation of neural integration of synaptic input. 
			Excitatory Postsynaptic Potentials(EPSP) increase the membrane potential of the postsynaptic neuron and excite the neuron toward firing.
			Inhibitory Postsynaptic Potentials(IPSP) hyperpolarize the postsynaptic neuron, thus inhibiting the neuron with respect to firing. %and inhibits the postsynaptic neuron with respect to firing.
			When the membrane potential at the axon hillock crosses the firing threshold, set to $-10mV$ in this simulation, an action potential is fired.
			%Figure is from http://techlab.bu.edu/resources/software_view/epsp_ipsp/
			(The figure is from the website, {\tiny{\emph{http://techlab.bu.edu/resources/software\_view/epsp\_ipsp/}}}, of the educational  ``\emph{EPSP IPSP}'' software, intended for illustration of EPSP and IPSP after synaptic transmissions).
% 			(The figure is found on the website of the educational ``\emph{EPSP IPSP}'' software, intended for illustration of EPSP and IPSP after synaptic transmissions).
				}
	\label{figIllustrationOfEPSPandIPSP}
\end{figure}


	Let the synaptic weight $\omega_{ij}$ be defined as the postsynaptic change in depolarization after one synaptic transmission. 	
	Synapse $j$'s contribution to the total change in depolarization after a time interval $\Delta t$ can be written as the number of transmissions in that interval scaled by the synaptic weight $\omega_{ij}$.
	%In discrete time simulations, this can be written as
	\begin{equation}
		\Delta v_{i}(\Delta t_n) = N_{j,\Delta t}\cdot\omega_{ij, t_{n-1}} \qquad,\; j\in\mathscr{D}
	\end{equation}
	where $N_{j,t_n}$ represents the number of transmissions in the synapse from neuron $j$ to neuron $i$ in the time interval $\Delta t_n$.
	The variable $\omega_{ij,t_{n-1}}$ represents the synaptic weight, updated at time $t_{n-1}$.

	In $\kappa M$, a continuous variable representing the present estimate of the inter--spike interval can be used instead of the integer number of transmissions. 
	This enables a higher resolution for the propagated signal and thus a smaller simulation error.
	For a time interval where the presynaptic activation level $\kappa_j$ is constant, synaptic flow of activation level can be written as
	\begin{equation}
		\kappa_{ij, t_n} = \frac{ \omega_{ij, t_n} }{ p_{isi}(\kappa_{j, t_n}) } \Delta t \qquad,\; j\in\mathscr{D}
	\end{equation}

	For a simulation with constant computational time steps $\Delta t = C_t$, this constant can further be incorporated into the variable that represents synaptic weight $\omega_{ij}$.
	We arrive at the equation for synaptic flow of activation level for constant time steps:
	\begin{equation}
		\kappa_{ij} = \frac{ \omega_{ij} }{ p_{isi}(\kappa_{j})} \qquad,\;j\in\mathscr{D}
		\label{eqSynapticTransmissionForKANN}
	\end{equation}
	
	When synaptic plasticity is introduced, it is important to remember that synaptic weight is scaled by the constant $C_t$.
	For consistency, it is important to scale synaptic plasticity by the same factor.


	%TODO Let this be the discussion for this chapter. (Do the summary in this section).
	\section{Implications of $\kappa$--Mathematics}
		Algebraic analysis of a node's activation level is possible when neural input is represented as a continuous flow.
		The propagation of information is represented by the distribution of a changed $\kappa$.
		This makes it possible to utilize a less confusing jargon when talking about neural activation level.
		Algebraic transfer functions can also be set up, making it possible to do computations on the filter properties of a neural network.

		Combined with the concept of synaptic flow and time windows, the $\kappa$ formalism enables a novel neural simulation scheme, the $\kappa$ simulation model($\kappa M$).
		By letting the activation level, $\kappa$, be propagated as a mechanistic function of the presynaptic neuron's firing frequency,
			neural network dynamics can be simulated, and eq. \ref{eqValueEquation} can be used to find the neuron's depolarization.
		Thus, the $\kappa M$ simulation model has elements from second as well as third generation $ANN$s.

		The concept of time windows from definition \ref{defTimeWindow} makes it possible to utilize equation \ref{eqValueEquation} to simulate the neuron's depolarization.
		Every time the neuron's activation level is altered, a new time window is initialized by updating the initial depolarization 
			value $v_0$ and saving the time of initiation, $t_0$.
		The depolarization value can be found for any time $t_v$ in a time window, by the equation
\begin{equation}
 	v(t_v) = \kappa - \left( \kappa - v_0 \right) e^{-at_v} 	\quad,\; t_v = t - t_0
	\label{eqValueEquationForEachTimeWindow}
\end{equation}

		The next firing time can be estimated by eq. \ref{eqEstimatedTimeToFiring}. %whenever a new time window is initialized.
		This makes it possible to have spike times with an intra--iteration time accuracy, and a near--continuous resolution for possible spike times can be accomplished.

















% FERDIG. Resten er utkommentert: Sj√• gjennom, om du vil.. (sikkert noke bra innhold, inni der..)


% 	\section{Summary, $\kappa M$ neuron simulation model}
% 	% - Kvar node er ansvarlig for √• oppdatere sin depol. som funksjon av depolarizing flow.
% 	% - 
% 		In this chapter, a novel neuron simulation model based on the algebraic solution to the $LIF$ neuron's depolarization is developed.
% 		The algebraic equation is found by solving the system's differential equations. %, and necessary concepts like synaptic flow and time windows enable a simulation model based on this equation.
% 		When considering depolarizing and hyperpolarizing input as flows, this equation can be utilized for simulating the neuron's depolarization.
% 		The concept of time windows enable these depolarization--altering flows to be dynamic, and an activation based ANN model similar to a second generation ANN can be used to simulate nodes with third generation ANN facilities.
% 		% TODO i siste discussion: Skriv om muligheten for 'transduction' av signal mellom 2.gen og 3.gen ANN ved KM.
% 		
% 		From equation \ref{eqEstimatedTimeToFiring} and \ref{eqEstimateOfInterSpikePeriod}, the next firing in addition to the immediate inter--spike interval can be estimated with a floating point accuracy.
% 		This enables a higher resolution of firing time and synaptic signal propagation, and a more accurate depolarization simulation is thought to be the result.
% 		% TODO TODO TODO Neste setning er litt upassende, her! TODO TODO TODO Skriv om! (Dette skal bare v√¶re en oppsummering, men eg f√∏ler at eg trenger noko meir enn setn. over..
% 		To further examine this element, simulation software is designed with the intention to compare the two models.
% 		The design and results of this comparison is presented in chapter \ref{chDesignAndTheroeticalComparison}.
% 		%To further examine this, simulation software is designed with the intention of comparing the different ways of simulating a spiking neuron.
% 		%To test whether this is the case, the two models are implemented and efficiency experiments are designed in chapter \ref{chExperimentalEfficiencyMeasurement}.
% 		
% 	%	Even if the $\kappa M$ neuron simulation model has the capability to compute the spike time of the neuron, spikes are not used as a means to propagate the signal through the neural network.
% 	%	The simulated firing is not directly involved in signal propagation(as in the $NIM$ model), but can be considered as an extra proficiency of the $\kappa M$ simulation model.
% 		
	

	
% 	\section{New Aspects to be Considered for the Novel Model}
% 		The use of the theory presented in this chapter introduce new aspects that have to be considered as well as opportunities for the simulator. % implementation.
% 		%The use of the theory presented in this chapter introduce a some new considerations and opportunities for the simulator. % implementation.
% 		%The use of the theory presented in this chapter introduce a some new considerations and opportunities for the implementation.
% 		Because the activation level $\kappa$ is updated many times before the neuron fires, time windows have to be utilized to be able to simulate utilizing the $\kappa M$. %a spiking neuron by $\kappa M$.
% 		From equation \ref{eqEstimatedTimeToFiring} and \ref{eqEstimateOfInterSpikePeriod}, the next firing and the inter--spike period can be estimated with a floating point accuracy.
% 		This enables a synaptic signal propagation of a number with a higher resolution, and the execution of an action potential at the computed firing time instant.
% 		
% 		When equation \ref{eqEstimatedTimeToFiring} have given an estimate that is in the present computational time step, an action potential is simulated.
% 		%When the estimated firing time is in the present time iteration, an action potential is simulated.
% 		The simulated firing is not involved in signal propagation as in the $NIM$ model, but is an additional capability for the $\kappa M$ simulation model.
% 		%The main reason for simulating the action potential in the $\kappa M$ is to compute mechanisms like STDP, as presented in appendix \ref{appendixSynapticPlasticity}.
% 		The neuron fires when the estimated task time is in the present computational time step.
% 		To be able to efficiently make use of this proactive firing time simulation scheme, a task scheduler have to be devised specifically for this purpose.
% 		%This proactive firing scheme in $\kappa M$ requires a task scheduler to be able to efficiently simulate the neuron.





%TODO  Skriv noke nytt, her. Skal flytte "Task Scheduling" til "General Design of Simulator"::"Time" Det er fortidlig √• ha det her.
		
% 		\subsection{Task Scheduling}
% 			
% 			Two alternatives for scheduling tasks have been tested for the simulator.
% 			The first is based on a continuously updated linked list of linked lists with tasks. %that can be considered a variable array.
% 			When a task is scheduled for execution e.g. in the iteration after the next, the object's pointer is inserted into the second inner list of the outer linked list.
% 			Before every time step, the first element of the outer list is popped and all the tasks of the inner list is inserted into \emph{pWorkTaskQueue}.
% 			This gives a list of lists that gives the relative time of scheduled tasks, where each list contains jobs scheduled for future time iterations.
% 			
% 			An alternative approach is to implement time scheduling by letting the \emph{time\_interface} abstract class have a variable \emph{double dEstimatedTaskTime}.
% 			This element is updated every time the neuron's firing time estimate is updated and checked by \emph{time\_class::doTask()} when time is iterated:
% 				If an element is scheduled for execution during the next computational time step, the pointer to that element is inserted into \emph{pWorkTaskQueue}.
% 			As introduced in section \ref{ssecTime}, this causes the task to be executed during the correct computational time step, 
%  			%This causes the task to be executed during the correct computational time step, 
% 				and the double precision floating point variable \emph{dEstimatedTaskTime} enables an intra--iteration time accuracy for tasks if \emph{pWorkTaskQueue} is
% 				 sorted by this variable.
% 
% 			The two methods was tested by comparing the total run time for a similar experiment set up.
% 			Because the second alternative is simpler to implement and thus simpler to maintain,
% 				and it was found to have about the same grade of efficiency(almost $5\%$ faster for the conducted experiment),
% 				%and have about the same grade of efficiency(about $5\%$ faster for the conducted experiment), 
% 				this approach is used for time scheduling in the implementation.
% 				%the alternative with the \emph{time\_interface::dEstimatedTaskTime} is used for time scheduling in this implementation.
% 			%The second alternative was somewhat more efficient($<5\%$ faster run time) in addition to being simpler to implement and maintain.
% 			%This alternative was therefore chosen.
% 			
% 			\subsubsection{Task Scheduling for Other Tasks}
% 				%The task scheduler utilize a variable from \emph{
% 				As the task scheduler use a member variable from \emph{class time\_interface}, task scheduling can be used for all classes that is part of the simulation.
% 				An important example of this is the \emph{synapse}: % The synaptic transmission for all output synapses of a node can therefore 
% 					When the neuron fires, the auron object of the node can write to all the node's output synapses' \emph{dEstimatedTaskTime} variable.
% 				The time can be written to the present time plus the predefined axonic delay before that synapse's transmission.
% 				In this way, a more efficient axon delay can be simulated with floating point accuracy.





	
% // vim:fdm=marker:fmr=//{,//}
