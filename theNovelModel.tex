
\section{Spiking Neuron Simulation Based on Synaptic Flow}
	\label{secDevelopmentOfTheNovelANNmodel}
	An intuitive leaky integrator is a bucket with a set of small holes at the bottom.
	%Because this system is simple to visualize, it is 
	If the LIF neuron is visualized as a leaky bucket with input from a gutter, excitatory synaptic input can be represented by an agent pouring cups of water into that gutter.
	%If the LIF neuron is visualized as a leaky bucket with input from a gutter, synaptic transmissions is represented by pouring cups of water into this gutter.
	When the number of agents pouring water into the gutter becomes very large and the size of each transmission is small, this can again be visualized as rain.
	%The resulting water level in the leaky bucket can be simulated by either counting the number of raindrops or by estimating the corresponding flow in the input gutter and utilizing the algebraic solution to find the water level.
	The resulting water level in the leaky bucket can either be simulated by counting the number of raindrops(and computing the size of the leakage in every computional time step)
	%The resulting water level in the leaky bucket can be simulated by either counting the number of raindrops(and computing the leakage after each computational time step)
		or by estimating the corresponding flow through the gutter and utilizing the algebraic solution to find the water level.
%%%%%
	%If the simulation has a bounded temporal accuracy(discrete time), the author believes that a more accurate simulation result can be achieved when the algebraic solution is utilized to simulate the systems value. 
	When the simulation has a bounded temporal accuracy(discrete time), it is found that a more accurate simulation result can be achieved when the algebraic solution is utilized to simulate the systems value.
	%TODO Dropp setninga over? NEI: første biten er jævla bra! 			Men det etter her er litt dårlig: avslører for mykje om kva eg finner ut?
%%                 %%                                                          %%                                                  %%                                              % input is represented as a flow.
	%This implies that fewer iterations are needed to accomplish some accuracy goal, and a more efficient simulator model is the result.
	In this section, the mathematics and necessary concepts for a flow simulation is developed and presented.




% 	The subthreshold integration of a LIF neuron can be visualized as a leaky bucket with input from a gutter.
% 	Excitatory synaptic input can further be represented by an agent pouring cups of water into that gutter.
% 	%The subthreshold integration of a LIF neuron can be thought of as a leaky bucket with small holes at the bottom.
% 	%If the LIF neuron is modelled as a leaky bucket with input from a gutter, excitatory synaptic input can be represented by pouring cups of water into that gutter. %this gutter.
% 	When the number of incoming synaptic connections are very large and the size of each transmission is small, this can again be visualized as rain.
% 	The resulting water level in the bucket can either be simulated by counting the number of rain drops and estimating the size of each, or by estimating the corresponding flow out of the gutter and utilizing the 
% 		algebraic solution to find the water level. %algebraic solution to the differential equations to find the water level.
% 	If the simulation has a bounded temporal resolution(discrete time), it is found that a more accurate simulation can be achieved by considering depolarizing flow instead of discrete synaptic transmissions.
% 	In this section, the mathematics and necessary concepts for flow simulation are developed and presented.

	\subsection{The Algebraic Solution to the LIF Neuron's Value}
	\label{ssecTheAlgebraicSolution}
		Subthreshold integration in the LIF neuron is defined by general leaky integrator's differential equations\cite{gerstnerKistler2002KAP04}.
		\begin{equation}
			\begin{split}
				\dot{v}(t)&= \dot{v}_{in}(t) - \dot{v}_{out}(t) \\
					&= I(t) - \alpha v(t)
			\end{split}
			%\nonumber
			\label{eqDifferentialEquation}
		\end{equation}
		The inflow is represented by $\dot{v}_{in}(t) = I(t)$, and $\dot{v}_{out}(t)$ represents the ``leakage'' of the neuron's depolarization value.
		The leakage is thus given as the neuron's present depolarization level scaled by the system's leakage constant $\alpha$.
		The algebraic solution to \ref{eqDifferentialEquation} is derived in appendix \ref{appendixAlgebraicSolution}.
		For time intervals where $\kappa$ and $\alpha$ are constant, it is found that the system's subthreshold depolarization is given by %can be found by TODO Skriv om! "is given by" er dårlig!
		\begin{equation}
			v(t_v) = \kappa - \left( \kappa - v_0 \right) e^{-at_v} 	\quad,\; \kappa = \frac{I}{\alpha} % \quad,\;t_v = t-t_0
			\label{eqValueEquation}
		\end{equation}

	
		The variable $v_0$ represents the initial value for the neuron's depolarization and $t_v$ is the time from the start of the considered time interval\mbox{($t_v = t - t_0$)}.
		Recall that equation \ref{eqValueEquation} only is valid for time intervals where $\kappa$ and $\alpha$ remain constant.
		To formalize such an interval for later discussions, the concept of time windows is introduced. % defined.
		\begin{mydef}
			A time window is a time interval where $\kappa$ and $\alpha$ are constants, within one inter--spike period.
			\label{defTimeWindow}
		\end{mydef}
		When the neuron's input flow is changed or the neuron fires an action potential, a new time window is initialized.
		The initial value $v_0$ can be found by computing the last value of the previous time window, and $t_0$ is acquired by saving the time of initiation for the new time window.


%TODO Lag figur på nytt! Endre litt på teksten som står (t_p -- time from start of period    er dårlig. Bl.a.)
%TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
\begin{figure}[htb!p]
    \centering
    \includegraphics[width=0.65\textwidth]{demonstrasjonAvUlikeKappaforVerdifunksjonen}
 	  \caption[Illustration of how time windows can be utilized to simulated the neuron by the algebraic equation]{
	%		A leaky integrator can be simulated by utilizing the concept of time windows.
			The figure shows how the concept of time windows enables the use of \eqref{eqValueEquation} for simulating the neuron's depolarization.
			In the time interval $t_p = [0, 100]$, $\kappa_0 = 0.7$ is valid.
			At time $t_p = 100$, $\kappa$ is changed to $\kappa_1 = 0.5$, before it finally is set to $\kappa_2 = 1$ at time $t_p = 150$.
			}
\end{figure}

	\subsection{The Action Potential}
	\label{ssecTheActionPotential}
	As introduced in sec. \ref{secBiologicalNeuralSystems}, the neuron fires an action potential when the depolarization value crosses the firing threshold.
	%In continuous time, 
	The firing time for a neuron in continuous time can therefore be found by the equation $v(t_f) = \tau$, where $\tau$ is the firing threshold for the neuron.
	It is shown in appendix \ref{appendixFiringTime} that the firing time, represented as the remainder of the current inter--spike period can be estimated by % is given by
\begin{equation}
	p_r(\kappa, v_0)  	= -\alpha^{-1} \, \ln \left( \frac{\kappa - \tau}{\kappa - v_0} \right) + t_r
	\label{eqEstimatedTimeToFiring}
\end{equation}

	As the equation for the remainder of the inter--spike period is derived from \eqref{eqValueEquation}, the estimate is only valid for as long as $\kappa$ and $\alpha$ remains constant.
	This means that when a new time window is initiated, the old firing time estimate becomes invalid.
%%
	%If the depolarizing inflow is defined to be constant during a computational time step, a firing that is estimated to happen during the present time iteration can not change prior to this time.
	%If the depolarizing inflow is defined to be constant during a computational time step, a firing time estimate during the present time step can not change before that time. %the neuron fires.
	If the depolarizing inflow is defined to be constant during a computational time step, a firing time estimate in the present computational time step can not change before that time. %the neuron fires.
	The estimated firing time can therefore be utilized as the actual firing time, and an action potential can be initiated at that precise moment.
%%
	The set of possible spike times thus have a near--continuous temporal resolution, only limited by the accuracy of the format used. %e.g. the double precision floating point format.
	If e.g. the double precision floating point format is utilized, the IEEE standard defines the smallest number to be given by an exponent of $-308$\cite{kreyszig8edKAP17}. 
	%For e.g. the double precision floating point format, the IEEE standard defines the smallest number to be given by an exponent of $-308$\cite{kreyszig8edKAP17}. 
	This implies an accuracy where the numbers are separated by a step down to $10^{-308}$ time units.
	%For a discussion about what this results in for the simulation error, it is referred to sec. \ref{ssecAnalysisOfErrorsForTheTwoModels}.
	If all tasks are executed according to estimated spike times, a task planned slightly before another will therefore be initiated before that task despite being scheduled in the same computational time step.
	% TODO Skriv om neste setning, slik at det bare er ei leddsetning!
	%In some situations, this will have a large effect on mechanisms defined by the relative spike times of two neurons, e.g. Spike--Time Dependent Plasticity as mentioned in appendix \ref{appendixSynapticPlasticity}.
	The ability to extract the relative spike time with hight precision enables a more accurate computation of mechanisms defined by the relative spike times of the two neurons.
	The most important such mechanism is Spike--Time Dependent Plasticity as mentioned in appendix \ref{appendixSynapticPlasticity:postsynapticMechanisms}.
	%This will have a large effect on mechanisms defined by the relative spike times of two neurons, e.g. Spike--Time Dependent Plasticity as mentioned in appendix \ref{appendixSynapticPlasticity:postsynapticMechanisms}. 

%TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
%TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO  Finn figur som viser AP. Skriv at dette er formen på det biologiske AP.
%TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 


%TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO HER ER EG!

	The perhaps most important effect of having a near--continuous temporal resolution for the simulation error is that the next inter--spike interval is initiated at the correct time. %computed time instant.
	After an action potential(and the predefined absolute refraction period), the neuron can start charging the membrane potential at the right time. %computed time instant. 
	%%
	% TODO Har eg definert "reactive firing scheme" tidligere?
	%With the reactive firing scheme in simulations utilizing numerical integration, the firing have to be delayed to the next iteration to preserve causality in a neural network. %TODO Finn referanse! TODO
	With the reactive firing scheme in simulations utilizing numerical integration, where the neuron fires as a reaction to the depolarizing going to suprathreshold levels, 
		the firing have to be delayed to the next iteration to preserve causality in a neural network. %TODO Finn referanse! TODO CITE TODO
	%With a discretization of possible spike times, the neuron have to wait for the iteration after the threshold crossing to preserve causality in the neural network.
	This  introduces a small delay of up to one computational time step before the neuron can start depolarizing again.
	%This gives a small delay of up to one computational time step before the neuron can start depolarizing again.
%% 										%% 																	%% 														%% 			har ikkje innført 	 efficiency som funksjon av accuracy, enda.
	%A precise initiation of the next inter--spike interval caused by the near--continuous temporal resolution for possible spike times removes this error mechanism, and might be important for the efficiency of the neural simulator. %xxx
	A precise initiation of the next inter--spike interval caused by the near--continuous temporal resolution for possible spike times removes this error mechanism, and might be important for the accuracy of the simulated depolarization.
	%A precise initiation of the next inter--spike interval will therefore remove an important error mechanisms in spiking neuron simulations.
	%%A precise initiation of the next inter--spike interval will remove an error mechanism that might give an important part of the total error in spiking neuron simulations that utilize numerical integration. %when simulating depolarization by numerical integration.
	%For a more elaborate discussion of the error induced by discrete possible spike times, it is referred to sec. \ref{ssecAnalysisOfErrorsForTheTwoModels}.
	For a more elaborate discussion of the error induced by the discretization of time and discrete possible spike times, it is referred to sec. \ref{ssecAnalysisOfErrorsForTheTwoModels}.

% XXX Er det for langt hopp? Vil gjerne gå over til neste section: synaptic flow of activation level.
	An inter--spike interval is finalized by the neuron firing an action potential, after which the neuron's depolarization is reset to the membrane resting potential before the process starts anew.
	%After an action potential, the neuron's depolarization is reset to the membrane resting potential and the next inter--spike interval starts.
	%After an action potential, the neuron's depolarization is reset to the membrane resting potential and the process starts anew.
	The total inter--spike interval can therefore be estimated as the remainder of the inter--spike period from the neuron's reset potential $v_r$.
\begin{equation}
	p_{isi}(\kappa) = p_r(\kappa, v_r)% IKKJE: + t_r
	\label{eqEstimateOfInterSpikePeriod}
\end{equation}
	This equation will show important when we next consider synaptic flow of activation level.
	
	%This process can be modelled by 


    \subsection{Synaptic Flow}
	\label{ssecSynapticFlow}
%	Neural input that changes the neuron's depolarization can be divided into two groups, a subclass of synaptic input that changes the postsynaptic neuron's depolarization and other depolarizing input.
%	Neural input that changes the neuron's depolarization can be classified into two sets, a subclass of synaptic input that changes the postsynaptic neuron's depolarization and other depolarizing input.
	Neural input that changes the neuron's depolarization can be separated into two sets, a subclass of synaptic input that changes the postsynaptic neuron's depolarization and other depolarizing input.
	%Other input include the activation of a sensory neuron as a consequence of the sensed signal, and is represented by the 
	The synaptic part of depolarizing input can be mediated through ligand--gated channels, as introduced in section \ref{ssecTheBiologicalSynapse}.
	%Synaptic input that alters the postsynaptic membrane potential can be mediated through ligand--gated channels, as introduced in section \ref{ssecTheBiologicalSynapse}.
	This class of neural input is what will be referred to as synaptic input in the remainder of this text.
	%This class of neural input will be referred to as synaptic input in the remainder of this text.
%%
%%%	Input that change the depolarization of the neuron comes in many forms. 
%	A class of these is a subset of synaptic input that alters the postsynaptic neuron's depolarization.
%	This class of input will be referred to as synaptic input in the remainder of this text.

%todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo 
%todo todo todo todo           Lag en figur som viser skematisk kva input eit neuron har(K_ij og xi_i)                   todo todo todo todo todo todo todo todo todo 
%todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo todo 

	Let all synaptic input be modelled as the flow $\kappa_{ij}$, where $j$ represents the presynaptic neuron and $i$ the receiving neuron.
	Other input that changes neuron $i$'s depolarization is represented by $\xi_i(t)$.
	The final value for the neuron's depolarization, $\kappa_i$, is defined by the sum of all the neuron's input flows.
	%The final value for the neuron's depolarization $\kappa_i$ is defined by the sum of all input flows for neuron $i$.
	The total inflow in the $n$'th iteration can therefore be written as

		\begin{equation}
% TODO HUGS: K = I/a : dermed må I være sum(k_ij + xi)*alpha
			% I_{i, t_n} = \sum_{j} \kappa_{ij, t_n} + \xi_{i, t_n}
			I_{i, t_n} = \kappa_{i,t_n} \cdot \alpha = \left( \sum_{j} \kappa_{ij, t_n} + \xi_i(t_n) \right) \cdot \alpha
			\label{eqSynapticIntegrationForKANN}
		\end{equation}

	The most important depolarizing input when it comes to neural signal processing, is synaptic input\cite{PrinciplesOfNeuralScience4edKAP10}.
	%Synaptic transmissions will therefore be the main focus of this section.
	The main focus of this section will therefore be synaptic transmissions.
	%The most important aspect for the neuron's signal processing capabilities comes as a consequence of synaptic transmission in networks of neurons, and will be the main focus in this section.
	The variable $\xi_i(t)$, representing other input, have different forms for different depolarizing sources and have to be modelled separately for each such source.
	%Other input $\xi_i(t)$ have different forms for different sources and have to be modelled separately for different such mechanisms.
	%The form of other input $\xi_i(t)$ varies for different sources of the signal and have to be modelled separately for each such mechanism. 
	%XXX BRA XXX: One example of another source for changing a neuron's depolarization is the instrumentation done by sensory neurons. %TODO TODO TODO Skriv om dette en plass, og referer dit!  

\begin{figure}[hbt!p]
	\centering
	\includegraphics[width=0.70\textwidth]{epsp_ipsp}
	\caption[Illustration of neural integration of synaptic input]{
			A simulation of neural integration of synaptic input. 
			Excitatory Postsynaptic Potentials(EPSP) increase the membrane potential of the postsynaptic neuron and thus excite the neuron toward firing.
			Inhibitory Postsynaptic Potentials(IPSP) hyperpolarizes the postsynaptic neuron, and inhibits the postsynaptic neuron with respect to firing.
			When the membrane potential at the axon hillock crosses the firing threshold, set to $-10mV$, an action potential is fired.
			%Figuren kommer fra http://techlab.bu.edu/resources/software_view/epsp_ipsp/
			%The simulation result presented in the figure is produced with the educational ``\emph{EPSP IPSP}'' software intended to illustrate EPSP and IPSP after synaptic transmissions.
			(The figure is found on the website of the educational ``\emph{EPSP IPSP}'' software intended for illustration of EPSP and IPSP after synaptic transmissions).
			% TODO Gjør forrige setninga mindre, og FÅ MED AT DET IKKJE ER EG SOM HAR LAGA DEN!
				}
	\label{figIllustrationOfEPSPandIPSP}
\end{figure}


	Let the synaptic weight $\omega_{ij}$ be defined as the postsynaptic change in depolarization after one synaptic transmission. 	
	%Let the synaptic weight $\omega_{ij}$ be defined as the postsynaptic change in depolarization after one transmission in the synapse.
	Synapse $j$'s contribution to the total change in depolarization after a time interval $\Delta t$ can therefore be defined as the number of transmissions in that interval, scaled by the synaptic weight $\omega_{ij}$.
	In discrete time simulations, this can be written as
	\begin{equation}
% TODO Skriv det som N
%		\Delta v_i(\Delta t) = f_j(t_{n-1})\Delta t \cdot\omega_{ij} = \frac{\omega_{ij}}{p_{isi}(t_{n-1}}
		%\Delta v_{i, t_n}(\Delta t) = N_{j,t_n}\cdot\omega_{ij, t_n} %								%= f_j(t_{n-1})\Delta t \cdot\omega_{ij} % = \frac{\omega_{ij}}{p_{isi}(t_{n-1}}
		\Delta v_{i}(\Delta t_n) = N_{j,\Delta t_n}\cdot\omega_{ij, t_{n-1}} %								%= f_j(t_{n-1})\Delta t \cdot\omega_{ij} % = \frac{\omega_{ij}}{p_{isi}(t_{n-1}}
	\end{equation}
	where the variable $N_{j,t_n}$ represents the number of transmissions from neuron $j$ in time interval $\Delta t_n$, and $\omega_{ij, t_{n-1}}$ represents the synaptic weight updated at time $t_{n-1}$.
	%where the number of transmissions is found by the last computed firing frequency of the presynaptic neuron $f_j(t_{n-1})$ multiplied by the length of the time interval $\Delta t$.

	In the flow simulation model($\kappa M$) presented in this text, a continuous variable representing the present estimate of the inter--spike interval can be propagated instead of the integer number of transmissions,
		enabling a higher resolution for the propagated signal.
	For a time interval where the presynaptic activation level $\kappa_j$ is constant(a time window for the presynaptic neuron), synaptic flow of activation level can be written as
	\begin{equation}
	%	\kappa_{ij} = \frac{ \omega_{ij} }{ p_{isi}(\kappa_{j})}\Delta t
		\kappa_{ij, t_n} = \frac{ \omega_{ij, t_n} }{ p_{isi}(\kappa_{j, t_n}) } \Delta t % TODO SKRIV kva \Delta t   er for noke! TODO TODO SKVIVE DET SOM FREKVENS, først? = f(t) \omega \cdot \Delta t
	\end{equation}

	If a simulation with constant computational time steps $\Delta t = C_t$ is considered, this constant can be incorporated into the equation for synaptic flow $\kappa_{ij}$.
	%If we let the simulation be carried out with constant time steps $\Delta t = C_t$, this constant can be incorporated into the equation for synaptic flow $\kappa_{ij}$.
	% ELLER:
	%Let the simulation be carried out with constant time steps $\Delta t = C_t$.
	%This constant can then be incorporated into the equation for synaptic flow $\kappa_{ij}$.
	We arrive at the equation for synaptic flow of activation level for constant time steps:
	\begin{equation}
		\kappa_{ij} = \frac{ \omega_{ij} }{ p_{isi}(\kappa_{j})}
		\label{eqSynapticTransmissionForKANN}
	\end{equation}
	
	When synaptic plasticity is introduced, it is important to remember that synaptic weight is scaled by the constant $C_t$.
	For consistency, it is important to scale synaptic plasticity by the same factor.

%[Her stod tidligare en analyse av feilen for de to ANN modellene]. Dette er flyttet inn i analysisOfTheTwoModels.tex



	\section{New Aspects to be Considered for the Novel Model}
		Skriv om pEstimatedTaskTime. ---At eg trenger det, og korleis gjennomføre dette.
		\subsection{Synaptic Transmission as the Derivative}
		\subsection{Recalculation of $\kappa$}
		\subsection{Task Scheduling}
			INTRO: Sei at tradisjonellt har spatiotemporal effects vore simulert ved å legge causal elements sequentially in a linked list. CITE! %TODO TODO! FINN CITE TODO TODO
			Pass på å ikkje trakke for mykje i samme grøten som kapittel 3! (der snakker eg litt om dette, men ikkje mykje trur eg).
			% TODO Skal eg ha neste to subsections, her? Dette er meir implementeringsspesifikt! TODO Ta vekk.
			%\subsubsection{Task Scheduling by Continuously Updated Linked List of Events}
			%\subsubsection{Task Scheduling by Checking a Member Variable dEstimatedTaskTime}


	
% // vim:fdm=marker:fmr=//{,//}
